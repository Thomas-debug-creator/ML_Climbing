{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import auth\n","auth.authenticate_user()\n","import gspread\n","from google.auth import default\n","creds, _ = default()\n","\n","gc = gspread.authorize(creds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL4ELfZp33qP","executionInfo":{"status":"ok","timestamp":1655216354415,"user_tz":-120,"elapsed":2162,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"outputId":"f6bc248f-8c9a-459a-f9cc-2c0df30cac63"},"id":"RL4ELfZp33qP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install torchdata"],"metadata":{"id":"1V1qLQNh4IKg","executionInfo":{"status":"ok","timestamp":1655216357201,"user_tz":-120,"elapsed":2789,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fa8a535-4b95-4ba7-9ffc-3b32be45f1e2"},"id":"1V1qLQNh4IKg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n"]}]},{"cell_type":"markdown","source":["## Previous Transformer"],"metadata":{"id":"yFfiTLn4UPu3"},"id":"yFfiTLn4UPu3"},{"cell_type":"code","execution_count":null,"id":"impaired-purpose","metadata":{"id":"impaired-purpose"},"outputs":[],"source":["import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, src_mask):\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output"]},{"cell_type":"code","execution_count":null,"id":"several-brazilian","metadata":{"id":"several-brazilian"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"markdown","source":["# Get the data"],"metadata":{"id":"RA9rqKhC4TGI"},"id":"RA9rqKhC4TGI"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import json\n","import itertools\n"],"metadata":{"id":"PaBe3iLH4Zdo"},"id":"PaBe3iLH4Zdo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["main_path = '/content/drive/MyDrive/MyProject/Moonboard/Videos/' # To modify with your path\n","my_path = '/content/drive/MyDrive/MyProject/Moonboard/' # To modify with your path\n","move_seq_path = my_path + 'MoveSeqs/'\n","holds_seq_path = my_path + 'HoldsSeqs/'"],"metadata":{"id":"06hXfmDq4Si_"},"id":"06hXfmDq4Si_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["worksheet = pd.read_csv(my_path + 'videos.csv')\n","worksheet = worksheet.iloc[:,1:]\n","worksheet"],"metadata":{"id":"riYjop5R4Wt4","executionInfo":{"status":"ok","timestamp":1655216357205,"user_tz":-120,"elapsed":43,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/","height":677},"outputId":"4486872d-0f57-482f-f440-c7147dc64b37"},"id":"riYjop5R4Wt4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        name\n","0   0000.mp4\n","1   0001.mp4\n","2   0002.mp4\n","3   0003.mp4\n","4   0004.mp4\n","5   0005.mp4\n","6   0006.mp4\n","7   0007.mp4\n","8   0008.mp4\n","9   0009.mp4\n","10  0010.mp4\n","11  0011.mp4\n","12  0012.mp4\n","13  0013.mp4\n","14  0014.mp4\n","15  0015.mp4\n","16  0016.mp4\n","17  0017.mp4\n","18  0018.mp4\n","19  0019.mp4"],"text/html":["\n","  <div id=\"df-88e7c8b9-12c1-4067-bcb2-d0d0abe08d82\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0001.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0002.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0003.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0004.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0005.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0006.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0007.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0008.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0009.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0010.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0011.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0012.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0013.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0014.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0015.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0016.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0017.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0018.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0019.mp4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e7c8b9-12c1-4067-bcb2-d0d0abe08d82')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-88e7c8b9-12c1-4067-bcb2-d0d0abe08d82 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-88e7c8b9-12c1-4067-bcb2-d0d0abe08d82');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":341}]},{"cell_type":"markdown","source":["### Test with one sequence"],"metadata":{"id":"9NhH6rtRCPb-"},"id":"9NhH6rtRCPb-"},{"cell_type":"code","source":["video = worksheet.iloc[0,0]\n","target = pd.read_csv(move_seq_path + video + '_MOVE_SEQ.csv').iloc[:,2:]\n","\n","target_coords = target.iloc[:,:2]\n","target_tokens = target.iloc[:,2]"],"metadata":{"id":"T89LpkVQ4f23"},"id":"T89LpkVQ4f23","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target_coords"],"metadata":{"id":"iiqL93nLMuYl"},"id":"iiqL93nLMuYl","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We discretize the coordinates on a grid by rounding them up"],"metadata":{"id":"G8cmGfV9I8d_"},"id":"G8cmGfV9I8d_"},{"cell_type":"code","source":["nb_decimals = 2\n","def standardize_df(df):\n","    return df.round(nb_decimals)"],"metadata":{"id":"vugmV2XkIaqG"},"id":"vugmV2XkIaqG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_coords = standardize_df(target_coords)\n","target_coords"],"metadata":{"id":"8NjO0VsUIsGT","executionInfo":{"status":"ok","timestamp":1655216357207,"user_tz":-120,"elapsed":37,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"f6bba214-709a-4f31-a95a-56a262f91a48"},"id":"8NjO0VsUIsGT","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      x     y\n","0  0.24  0.63\n","1  0.42  0.57\n","2  0.42  0.40\n","3  0.21  0.66\n","4  0.74  0.32\n","5  0.46  0.57\n","6  0.40  0.41"],"text/html":["\n","  <div id=\"df-54b29090-26fe-48fe-a22d-41bbea736205\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.24</td>\n","      <td>0.63</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.42</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.42</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.21</td>\n","      <td>0.66</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.74</td>\n","      <td>0.32</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.46</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.40</td>\n","      <td>0.41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54b29090-26fe-48fe-a22d-41bbea736205')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54b29090-26fe-48fe-a22d-41bbea736205 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54b29090-26fe-48fe-a22d-41bbea736205');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":345}]},{"cell_type":"markdown","source":["We define a position vocabulary for the discretized coordinates"],"metadata":{"id":"dpIFxBrrJHmq"},"id":"dpIFxBrrJHmq"},{"cell_type":"code","source":["position_vocabulary = {i/(10**nb_decimals) : i for i in range(10**nb_decimals)}\n","position_vocabulary[-1] = 10**nb_decimals\n","\n","# Convert the coordinates using the above defined tokenizer\n","target_coords[\"x\"].replace(position_vocabulary, inplace = True)\n","target_coords[\"y\"].replace(position_vocabulary, inplace = True)\n","\n","target_coords"],"metadata":{"id":"vOMRXxh5JPkZ","executionInfo":{"status":"ok","timestamp":1655216357208,"user_tz":-120,"elapsed":36,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"69b0c8b8-ef49-46a7-92f9-ee0aa15b89ff"},"id":"vOMRXxh5JPkZ","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      x     y\n","0  24.0  63.0\n","1  42.0  57.0\n","2  42.0  40.0\n","3  21.0  66.0\n","4  74.0  32.0\n","5  46.0  57.0\n","6  40.0  41.0"],"text/html":["\n","  <div id=\"df-03008809-017a-4b64-a923-2c3196956eb5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24.0</td>\n","      <td>63.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>42.0</td>\n","      <td>40.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21.0</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>74.0</td>\n","      <td>32.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>46.0</td>\n","      <td>57.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>40.0</td>\n","      <td>41.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03008809-017a-4b64-a923-2c3196956eb5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-03008809-017a-4b64-a923-2c3196956eb5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-03008809-017a-4b64-a923-2c3196956eb5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":346}]},{"cell_type":"markdown","source":["In order to work with this sequence, we need to put it in a tensor"],"metadata":{"id":"AYUw1csDDxwV"},"id":"AYUw1csDDxwV"},{"cell_type":"code","source":["def convert_df_into_tensor(df):\n","    \"\"\"Concatenates all the rows of a dataframe into a big list of strings.\n","    WARNING: the column names are not registered, so the order has to be implicitly respected\"\"\"\n","    df_list = torch.empty(df.shape)\n","\n","    for i in range(df.shape[0]):\n","        df_list[i] = (torch.Tensor(df.iloc[i]))\n","\n","    # df_list = list(itertools.chain.from_iterable(df_list))\n","    \n","    return df_list\n","\n","target_coords_tensor = convert_df_into_tensor(target_coords)"],"metadata":{"id":"uo1sO2c0DxGr"},"id":"uo1sO2c0DxGr","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we generate permutations of the target sequence to get the input sequences. We also generate the token sequence (0,1,2...), which will be shuffled accordingly to get the target output sequence. We also generate the trivial token vocabulary"],"metadata":{"id":"eJIQGhBXE51c"},"id":"eJIQGhBXE51c"},{"cell_type":"code","source":["MAX_LENGTH = 20\n","def generate_token_sequences(nb_seqs, length = MAX_LENGTH):\n","  token_sequence = torch.linspace(0,length-1, length, dtype=torch.int64)\n","  return token_sequence.repeat(nb_seqs, 1)\n","\n","token_vocabulary = {f'hold_{i}' : i for i in range(MAX_LENGTH + 1)} # the last one is the additional token that will be used for padding\n","inverse_token_vocabulary = {i: f'hold_{i}' for i in range(MAX_LENGTH + 1)}"],"metadata":{"id":"9P5l84SFPgzJ"},"id":"9P5l84SFPgzJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad_target_coords(target_coords_tensor):\n","  \"\"\"NEW: pad with the last hold instead of an imaginary hold\"\"\"\n","  padded_seq = torch.empty((MAX_LENGTH, 2))\n","  padded_seq[:target_coords_tensor.shape[0], :] = target_coords_tensor\n","  padded_seq[target_coords_tensor.shape[0]:, :] = target_coords_tensor[-1]\n","\n","  padded_indices = torch.full((MAX_LENGTH,1), fill_value = target_coords_tensor.shape[0])\n","  padded_indices[:target_coords_tensor.shape[0]] = torch.arange(0,target_coords_tensor.shape[0]).view(-1,1)\n","\n","  return padded_seq, padded_indices"],"metadata":{"id":"UVa2_AYld87-"},"id":"UVa2_AYld87-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# From the target sequence, generate random holds sequence for input \n","def generate_input_sequences(target, nb_perms = 2):\n","  input_seqs = []\n","  output_seqs = []\n","\n","  last_index = target.shape[0]-1\n","  target_padded, padded_indices = pad_target_coords(target)\n","\n","  input_token_seqs = generate_token_sequences(nb_seqs = nb_perms, length = target.shape[0])\n","  output_token_seqs = []\n","  for n in range(nb_perms):\n","    full_input = torch.cat((target, input_token_seqs[n].view(-1,1)),1)\n","    shuffled_input = torch.Tensor(np.random.permutation(full_input[:-1]))\n","\n","    shuffled_input = torch.cat((shuffled_input,torch.cat((target_padded[last_index:],padded_indices[last_index:]),1)),0)\n","\n","\n","    input_seqs.append((torch.Tensor(shuffled_input[:,:2])))\n","    output_token_seqs.append(torch.Tensor(shuffled_input[:,2:]).view(-1))\n","    output_seqs.append(target_padded)\n","    \n","\n","  return input_seqs, output_seqs, torch.vstack(output_token_seqs)\n","\n","# target_coords_tensor = pad_target_coords(target_coords_tensor)\n","input_seqs, output_seqs, output_token_seqs = generate_input_sequences(target_coords_tensor)"],"metadata":{"id":"G1u1SaoH9czb"},"id":"G1u1SaoH9czb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_seqs "],"metadata":{"id":"tLI04l18PdL8","executionInfo":{"status":"ok","timestamp":1655216357669,"user_tz":-120,"elapsed":491,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"63eb77e1-645d-476f-f7b6-83e6124c4d06"},"id":"tLI04l18PdL8","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[24., 63.],\n","         [42., 57.],\n","         [42., 40.],\n","         [21., 66.],\n","         [74., 32.],\n","         [46., 57.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.]]), tensor([[24., 63.],\n","         [42., 57.],\n","         [42., 40.],\n","         [21., 66.],\n","         [74., 32.],\n","         [46., 57.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.]])]"]},"metadata":{},"execution_count":351}]},{"cell_type":"markdown","source":["Finally, we have to pad the sequences"],"metadata":{"id":"JGMRrhfqHFpI"},"id":"JGMRrhfqHFpI"},{"cell_type":"code","source":["# We define a function to generate a dummy input sequence of length MAX_LENGTH\n","def generate_dummy_sequence(dummy_char = -1):\n","  return torch.full((MAX_LENGTH, 2), fill_value = dummy_char)\n","\n","dummy_seq = generate_dummy_sequence()\n","outputs = output_seqs + [dummy_seq]\n","inputs = input_seqs + [dummy_seq]"],"metadata":{"id":"AjI0I8T5IVhU"},"id":"AjI0I8T5IVhU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now we use this function to pad the coordinates sequences\n","inputs_coords = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=position_vocabulary[-1])\n","outputs_coords = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=position_vocabulary[-1])\n","\n","\n","# print(inputs_coords)"],"metadata":{"id":"Qvj42rJzHy8O"},"id":"Qvj42rJzHy8O","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To get the full input token sequences, we just generate them with length = MAX_LENGTH\n","inputs_token_seqs = generate_token_sequences(nb_seqs = inputs_coords.shape[0] - 1, length = MAX_LENGTH)\n","inputs_token_seqs[:,output_token_seqs.shape[1]:] = MAX_LENGTH\n","# To get the full target token sequences, we take the input ones and replace the first part (non padded) by the target sequences previously generated\n","# output_token_seqs = torch.where()"],"metadata":{"id":"FWvVaRWLCV-X"},"id":"FWvVaRWLCV-X","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now have 4 list:\n","- output_seqs (nb_perms, len(sequence), 2) containing the coordinates and the limbs of the target holds sequence, ordered, repeated nb_perms times\n","- input_seqs (nb_perms, len(sequence), 2), same, but the nb_perms objects are permuted version of the target sequence\n","- input_token_seqs (nb_perms, len(sequence)) containing the numbers from 0 to len(sequence) - 1, representing the holds in the input sequence\n","- output_token_seqs (nb_perms, len(sequence)), same, but they are permuted in the same way as the coordinates, so that we have the actual target sequence to look for"],"metadata":{"id":"r3UaMoP_F2QQ"},"id":"r3UaMoP_F2QQ"},{"cell_type":"code","source":["print(inputs_token_seqs.shape)"],"metadata":{"id":"n3tSHx5FFxRL","executionInfo":{"status":"ok","timestamp":1655216357673,"user_tz":-120,"elapsed":60,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2c40e4e-ff26-4943-e6ed-acc60057b408"},"id":"n3tSHx5FFxRL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 20])\n"]}]},{"cell_type":"code","source":["outputs_token_seqs = inputs_token_seqs\n","outputs_token_seqs[:,:output_token_seqs.shape[1]] = output_token_seqs\n","print(outputs_token_seqs.shape)"],"metadata":{"id":"tqbI7mv9F0Hq","executionInfo":{"status":"ok","timestamp":1655216357673,"user_tz":-120,"elapsed":51,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0b58b59-641e-4bcb-f089-2fb8cdbf0c84"},"id":"tqbI7mv9F0Hq","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 20])\n"]}]},{"cell_type":"markdown","source":["Now, in order to work (?), the Transformer should complete the sequences by looking at a concatenation of the inputs and outputs. We do so by obtaining 2 sequences of length 39, one made of the 20 inputs and first 19 outputs, this will be our INPUT. The other is made of the last 19 inputs and the 20 outputs, this is our OUTPUT."],"metadata":{"id":"PhtaQOW5JUnT"},"id":"PhtaQOW5JUnT"},{"cell_type":"code","source":["inputs_tokens_cat = torch.cat((inputs_token_seqs, outputs_token_seqs[:,:-1]), dim=1)\n","outputs_tokens_cat = torch.cat((inputs_token_seqs[:,1:], outputs_token_seqs), dim=1)\n","inputs_coords_cat = torch.cat((inputs_coords, outputs_coords[:,:-1]), dim=1)\n","outputs_coords_cat = torch.cat((inputs_coords[:,1:], outputs_coords), dim=1)"],"metadata":{"id":"Ryy9sfQGBt_-"},"id":"Ryy9sfQGBt_-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs_coords_cat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVSnfGJyj7G2","executionInfo":{"status":"ok","timestamp":1655216357675,"user_tz":-120,"elapsed":46,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"outputId":"4bb97221-560f-42c4-f0b0-08a5c17afc85"},"id":"rVSnfGJyj7G2","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[21., 66.],\n","         [46., 57.],\n","         [42., 57.],\n","         [42., 40.],\n","         [24., 63.],\n","         [74., 32.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [24., 63.],\n","         [42., 57.],\n","         [42., 40.],\n","         [21., 66.],\n","         [74., 32.],\n","         [46., 57.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.]],\n","\n","        [[42., 57.],\n","         [74., 32.],\n","         [46., 57.],\n","         [42., 40.],\n","         [21., 66.],\n","         [24., 63.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [24., 63.],\n","         [42., 57.],\n","         [42., 40.],\n","         [21., 66.],\n","         [74., 32.],\n","         [46., 57.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.],\n","         [40., 41.]],\n","\n","        [[-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.],\n","         [-1., -1.]]])"]},"metadata":{},"execution_count":358}]},{"cell_type":"markdown","source":["### Now that we have all of these functions, we can process the entire dataframe by reading the data for all sequences."],"metadata":{"id":"fGNYxOCOQ0CB"},"id":"fGNYxOCOQ0CB"},{"cell_type":"code","source":["def prepare_data(sheet, nb_perms = 30):\n","  \"\"\"Returns 2 lists of arrays containing all sequences of holds and moves for each climb\"\"\"\n","  input_seqs = []\n","  output_seqs = []\n","  output_token_seqs = []\n","\n","  inputs_tokens = torch.Tensor()\n","  outputs_tokens = torch.Tensor()\n","\n","  for i in range(sheet.shape[0]):\n","    if i%10 == 0:\n","      print(f'Preparing data for video {i}/{sheet.shape[0] - 1}')\n","    video = sheet.iloc[i,0]\n","    try:\n","      target = pd.read_csv(move_seq_path + video + '_MOVE_SEQ.csv').iloc[:,2:]\n","\n","      target_coords = target.iloc[:,:2]\n","      target_tokens = target.iloc[:,2]\n","    except FileNotFoundError:\n","      continue\n","\n","    if(target_coords.shape[0] > 4):\n","      try:\n","        target_coords = standardize_df(target_coords)\n","        target_coords[\"x\"].replace(position_vocabulary, inplace = True)\n","        target_coords[\"y\"].replace(position_vocabulary, inplace = True)\n","\n","        target_coords_tensor = convert_df_into_tensor(target_coords)\n","        \n","        input_seqs_video, output_seqs_video, output_token_seqs_video = generate_input_sequences(target_coords_tensor, nb_perms=nb_perms)\n","        input_seqs += input_seqs_video\n","        output_seqs += output_seqs_video\n","\n","        # Copy the shuffled token sequences and add them to the list\n","        input_token_seqs = generate_token_sequences(nb_perms)\n","        input_token_seqs[:,output_token_seqs_video.shape[1]:] = MAX_LENGTH # the last ones are padded with the additional token\n","        outputs_token_seqs = torch.clone(input_token_seqs)\n","        outputs_token_seqs[:,:output_token_seqs_video.shape[1]] = output_token_seqs_video\n","\n","        inputs_tokens_cat = torch.cat((input_token_seqs, outputs_token_seqs[:,:-1]), dim=1)\n","        outputs_tokens_cat = torch.cat((input_token_seqs[:,1:], outputs_token_seqs), dim=1)\n","        \n","\n","        inputs_tokens = torch.cat((inputs_tokens, inputs_tokens_cat))\n","        outputs_tokens = torch.cat((outputs_tokens, outputs_tokens_cat))\n","\n","      except TypeError:\n","          continue\n","\n","  # Pad the sequences\n","  dummy_seq = generate_dummy_sequence()\n","  outputs = output_seqs + [dummy_seq]\n","  inputs = input_seqs + [dummy_seq]\n","\n","  inputs_coords = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=position_vocabulary[-1])\n","  outputs_coords = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=position_vocabulary[-1])\n","\n","\n","  # Remove the dummy sequence\n","  nb_seqs = inputs_coords.shape[0] - 1\n","  inputs_coords = inputs_coords[:nb_seqs]\n","  outputs_coords = outputs_coords[:nb_seqs]\n","\n","\n","  inputs_coords_cat = torch.cat((inputs_coords, outputs_coords[:,:-1]), dim=1)\n","  outputs_coords_cat = torch.cat((inputs_coords[:,1:], outputs_coords), dim=1)\n","\n","  return inputs_coords_cat, outputs_coords_cat, inputs_tokens, outputs_tokens\n","\n","inputs_coords, outputs_coords, inputs_tokens, outputs_tokens = prepare_data(worksheet, nb_perms=30)\n","print(f'Prepared sequences of shape {inputs_coords.shape}')"],"metadata":{"id":"FKtekkZkQzUL","executionInfo":{"status":"ok","timestamp":1655216357675,"user_tz":-120,"elapsed":39,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be6e6bdf-057f-4131-f81e-8a7dbc45d109"},"id":"FKtekkZkQzUL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing data for video 0/19\n","Preparing data for video 10/19\n","Prepared sequences of shape torch.Size([600, 39, 2])\n"]}]},{"cell_type":"code","source":["print(inputs_coords.shape)\n","print(outputs_coords.shape)\n","print(inputs_tokens.shape)\n","print(outputs_tokens.shape)"],"metadata":{"id":"9Q0oxPWYN07z","executionInfo":{"status":"ok","timestamp":1655216357676,"user_tz":-120,"elapsed":26,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3fb75d4-dc38-496d-aa83-9ae702136e13"},"id":"9Q0oxPWYN07z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([600, 39, 2])\n","torch.Size([600, 39, 2])\n","torch.Size([600, 39])\n","torch.Size([600, 39])\n"]}]},{"cell_type":"code","source":["inputs_coords[1]"],"metadata":{"id":"xB7gy7NI6Zja","executionInfo":{"status":"ok","timestamp":1655216357677,"user_tz":-120,"elapsed":21,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7ec4952-21da-4668-d813-1159fbeb16d4"},"id":"xB7gy7NI6Zja","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[42., 40.],\n","        [46., 57.],\n","        [74., 32.],\n","        [42., 57.],\n","        [24., 63.],\n","        [21., 66.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [24., 63.],\n","        [42., 57.],\n","        [42., 40.],\n","        [21., 66.],\n","        [74., 32.],\n","        [46., 57.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.],\n","        [40., 41.]])"]},"metadata":{},"execution_count":361}]},{"cell_type":"code","source":["inputs_tokens[1]"],"metadata":{"id":"M_losO9z6g1Z","executionInfo":{"status":"ok","timestamp":1655216358221,"user_tz":-120,"elapsed":561,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3fa83675-5b19-4be8-f96c-c79914b82c51"},"id":"M_losO9z6g1Z","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n","        14., 15., 16., 17., 18., 19.,  2.,  5.,  4.,  1.,  0.,  3.,  6.,  7.,\n","         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.])"]},"metadata":{},"execution_count":362}]},{"cell_type":"code","source":["outputs_tokens[1]"],"metadata":{"id":"X07PBd5j7R8m","executionInfo":{"status":"ok","timestamp":1655216358222,"user_tz":-120,"elapsed":14,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f353f3a-a709-41d5-9659-64fa7db5d377"},"id":"X07PBd5j7R8m","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n","        15., 16., 17., 18., 19.,  2.,  5.,  4.,  1.,  0.,  3.,  6.,  7.,  7.,\n","         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.])"]},"metadata":{},"execution_count":363}]},{"cell_type":"markdown","source":["Finally we concatenate all the data to create the input and target tensors"],"metadata":{"id":"tDgpGJPQWIhe"},"id":"tDgpGJPQWIhe"},{"cell_type":"code","source":["sequence_length = 2 * MAX_LENGTH - 1\n","input = torch.cat((inputs_coords, inputs_tokens.view(-1, sequence_length, 1)), 2)\n","target = outputs_tokens.view(-1)"],"metadata":{"id":"DfvGjt2gV-uH"},"id":"DfvGjt2gV-uH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(input.shape)\n","print(target.shape)"],"metadata":{"id":"XAxk7iyaXc2B","executionInfo":{"status":"ok","timestamp":1655216358222,"user_tz":-120,"elapsed":12,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1274000-1e47-456b-d4c2-d0bc66f14a87"},"id":"XAxk7iyaXc2B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([600, 39, 3])\n","torch.Size([23400])\n"]}]},{"cell_type":"markdown","source":["# At that point, we have all the input and output sequences prepared, both for coordinates and tokens. We now have to feed them into the Transformer."],"metadata":{"id":"rRkgb1m9WpyI"},"id":"rRkgb1m9WpyI"},{"cell_type":"markdown","source":["First, we adapt the position embedding to work with our data format"],"metadata":{"id":"28hM85bKVJ9A"},"id":"28hM85bKVJ9A"},{"cell_type":"code","source":["class PositionalEncoding_modified(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len = 5000):\n","        super(PositionalEncoding_modified, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.d_model = d_model\n","\n","\n","    def pe(self, position):\n","        pe = torch.zeros(position.shape[0], position.shape[1], self.d_model).to(device)\n","        \n","        # # Test by adding and scaling the 2 coords by div_term --> NOT GOOD\n","        # div_term = (torch.exp(torch.arange(0, self.d_model).float() * (-math.log(10000.0) / self.d_model))).view(1,-1).repeat(2,1).to(device)\n","\n","        # # Multiply by div_term for later\n","        # position_scaled = position @ div_term\n","\n","        # pe[:, :, 0::2] = torch.sin(position_scaled[:,:,0::2]) \n","        # pe[:, :, 1::2] = torch.cos(position_scaled[:,:,1::2])\n","\n","        # # Just embedd the x-coordinate\n","        div_term_half = (torch.exp(torch.arange(0, self.d_model,2).float() * (-math.log(10000.0) / self.d_model))).view(1,-1).to(device)\n","        div_term = torch.empty(self.d_model).view(1,-1)\n","        div_term[:,0::2] = div_term_half\n","        div_term[:,1::2] = div_term_half\n","\n","        pos_x_scaled = position[:,:,0].view(position.shape[0], position.shape[1],1) @ div_term\n","        pos_y_scaled = position[:,:,1].view(position.shape[0], position.shape[1],1) @ div_term\n","\n","\n","        # Embed x\n","        pe[:, :, 0::4] = torch.sin(pos_x_scaled[:,:,0::4]) \n","        pe[:, :, 1::4] = torch.cos(pos_x_scaled[:,:,1::4]) \n","\n","        # Embed y\n","        pe[:, :, 2::4] = torch.sin(pos_y_scaled[:,:,2::4]) \n","        pe[:, :, 3::4] = torch.cos(pos_y_scaled[:,:,3::4]) \n","\n","        return pe\n","\n","\n","    def forward(self, x_encoded, coords):\n","        pos_emb = self.pe(coords)\n","        y = x_encoded + pos_emb\n","        return self.dropout(y)"],"metadata":{"id":"xQwR4-5dVWCA"},"id":"xQwR4-5dVWCA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Test the position embedding with no token embedding for now (keeping the 30 holds sequence)\n","# x = input[0].view(1,30,3).to(device)\n","# # print(x)\n","# pos_model = PositionalEncoding_modified(MAX_LENGTH)\n","# pos_emb = pos_model(x[:,:,2], x[:,:,:2])\n","# # pos_emb"],"metadata":{"id":"QijyqCKdViZm"},"id":"QijyqCKdViZm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerModel_modified(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel_modified, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding_modified(ninp, dropout)\n","        self.regular_pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, src_mask):\n","        src_encoded = self.encoder(src[:,:,2].int()) * math.sqrt(self.ninp)\n","        #Position embedding based on the coordinates\n","        src = self.pos_encoder(src_encoded, src[:,:,:2])\n","        #Add also regular position embedding\n","        src = self.regular_pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output"],"metadata":{"id":"6CWAn2cBbSpK"},"id":"6CWAn2cBbSpK","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Actual use of the transformer"],"metadata":{"id":"zOp-Q8nCVW6e"},"id":"zOp-Q8nCVW6e"},{"cell_type":"code","source":["train_per, val_per = 0.6, 0.2\n","train_size = int(train_per * input.shape[0])\n","target_train_size= train_size * input.shape[1]\n","val_size = int(val_per * input.shape[0])\n","target_val_size= val_size * input.shape[1]\n","\n","device = torch.device(\"cpu\")\n","train_data = input[:train_size].to(device)\n","train_target = target[:target_train_size].to(device)\n","val_data = input[train_size: train_size + val_size].to(device)\n","val_target = target[target_train_size: target_train_size + target_val_size].to(device)\n","test_data = input[train_size + val_size:].to(device)\n","test_target = target[target_train_size + target_val_size:].to(device)"],"metadata":{"id":"PXo_vQzrYlKo"},"id":"PXo_vQzrYlKo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bptt = 100\n","def get_batch(input_source, target_source, i):\n","    i_target = input_source.shape[1] * i\n","    target_seq_len = min(bptt*input_source.shape[1], len(target_source) - input_source.shape[1] - i_target)\n","    seq_len = min(bptt, len(input_source) - 1 - i)\n","    data = input_source[i:i+seq_len]\n","    target = target_source[i_target:i_target+target_seq_len].long()\n","    return data, target\n","\n","data, targets = get_batch(train_data, train_target,  100)\n","print(data.shape, targets.shape)"],"metadata":{"id":"FsU8H1rNY8jS","executionInfo":{"status":"ok","timestamp":1655216358223,"user_tz":-120,"elapsed":10,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db2ebbdf-b67a-4015-d0a2-f70703ce64e2"},"id":"FsU8H1rNY8jS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 39, 3]) torch.Size([3900])\n"]}]},{"cell_type":"code","source":["ntokens = MAX_LENGTH + 1# the size of vocabulary\n","emsize = 512 # embedding dimension\n","nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","dropout = 0.2 # the dropout value\n","model = TransformerModel_modified(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"],"metadata":{"id":"oq8YbRSfYCeE"},"id":"oq8YbRSfYCeE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bptt = 100\n","# Just a test to check the whole Transformer's application\n","src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","src, targets = get_batch(train_data, train_target, 0)\n","print(\"data \", data.shape)\n","src_encoded = model.encoder(src[:,:,2].int()) * math.sqrt(model.ninp)\n","print(\"encoded \", src_encoded.shape)\n","src = model.pos_encoder(src_encoded, src[:,:,:2])\n","output = model.transformer_encoder(src, src_mask)\n","output = model.decoder(output)"],"metadata":{"id":"VITHeczTYXub","executionInfo":{"status":"ok","timestamp":1655216359691,"user_tz":-120,"elapsed":1475,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6dba9176-b2b1-424b-821e-785f733e14ec"},"id":"VITHeczTYXub","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data  torch.Size([100, 39, 3])\n","encoded  torch.Size([100, 39, 512])\n"]}]},{"cell_type":"code","execution_count":null,"id":"durable-transport","metadata":{"id":"durable-transport"},"outputs":[],"source":["import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 4.5*10**-4 # learning rate\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.96), eps=10**(-8), weight_decay=4.5**-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train():\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, train_target, i)\n","        optimizer.zero_grad()\n","        if data.size(0) != bptt:\n","            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        log_interval = 1\n","        if batch % log_interval == 0 and batch > 0:\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n","                  'lr {:02.2f} | ms/batch {:5.2f} | '\n","                  'loss {:5.2f} | ppl {:8.2f}'.format(\n","                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n","                    elapsed * 1000 / log_interval,\n","                    cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(eval_model, data_source, target_source):\n","    eval_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, data_source.size(0) - 1, bptt):\n","            data, targets = get_batch(data_source, target_source, i)\n","            if data.size(0) != bptt:\n","                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","            output = eval_model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += len(data) * criterion(output_flat, targets).item()\n","    return total_loss / (len(data_source) - 1)"]},{"cell_type":"code","execution_count":null,"id":"virgin-muscle","metadata":{"id":"virgin-muscle","executionInfo":{"status":"ok","timestamp":1655216470846,"user_tz":-120,"elapsed":111159,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fefbb456-a48c-4232-85af-01d93667c44f"},"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 |     1/    3 batches | lr 0.00 | ms/batch 5525.71 | loss  7.18 | ppl  1312.65\n","| epoch   1 |     2/    3 batches | lr 0.00 | ms/batch 3280.56 | loss  2.44 | ppl    11.50\n","| epoch   1 |     3/    3 batches | lr 0.00 | ms/batch 2647.08 | loss  2.62 | ppl    13.71\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 13.23s | valid loss  2.58 | valid ppl    13.16\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |     1/    3 batches | lr 0.00 | ms/batch 10673.17 | loss  3.40 | ppl    30.04\n","| epoch   2 |     2/    3 batches | lr 0.00 | ms/batch 4094.71 | loss  1.70 | ppl     5.45\n","| epoch   2 |     3/    3 batches | lr 0.00 | ms/batch 1529.45 | loss  1.08 | ppl     2.94\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 17.28s | valid loss  2.53 | valid ppl    12.49\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |     1/    3 batches | lr 0.00 | ms/batch 5045.30 | loss  2.86 | ppl    17.44\n","| epoch   3 |     2/    3 batches | lr 0.00 | ms/batch 2456.39 | loss  1.39 | ppl     4.00\n","| epoch   3 |     3/    3 batches | lr 0.00 | ms/batch 1439.93 | loss  1.21 | ppl     3.36\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time:  9.89s | valid loss  2.30 | valid ppl     9.96\n","-----------------------------------------------------------------------------------------\n","| epoch   4 |     1/    3 batches | lr 0.00 | ms/batch 5065.47 | loss  2.03 | ppl     7.59\n","| epoch   4 |     2/    3 batches | lr 0.00 | ms/batch 2520.93 | loss  1.13 | ppl     3.10\n","| epoch   4 |     3/    3 batches | lr 0.00 | ms/batch 1487.86 | loss  0.87 | ppl     2.39\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 10.10s | valid loss  2.39 | valid ppl    10.93\n","-----------------------------------------------------------------------------------------\n","| epoch   5 |     1/    3 batches | lr 0.00 | ms/batch 5065.67 | loss  2.29 | ppl     9.89\n","| epoch   5 |     2/    3 batches | lr 0.00 | ms/batch 2511.36 | loss  1.18 | ppl     3.25\n","| epoch   5 |     3/    3 batches | lr 0.00 | ms/batch 1440.85 | loss  0.96 | ppl     2.60\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time:  9.96s | valid loss  2.08 | valid ppl     8.02\n","-----------------------------------------------------------------------------------------\n","| epoch   6 |     1/    3 batches | lr 0.00 | ms/batch 5115.43 | loss  1.81 | ppl     6.09\n","| epoch   6 |     2/    3 batches | lr 0.00 | ms/batch 2515.09 | loss  0.99 | ppl     2.69\n","| epoch   6 |     3/    3 batches | lr 0.00 | ms/batch 1448.26 | loss  0.84 | ppl     2.33\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 10.03s | valid loss  2.18 | valid ppl     8.87\n","-----------------------------------------------------------------------------------------\n","| epoch   7 |     1/    3 batches | lr 0.00 | ms/batch 6349.27 | loss  1.77 | ppl     5.88\n","| epoch   7 |     2/    3 batches | lr 0.00 | ms/batch 2595.91 | loss  0.93 | ppl     2.52\n","| epoch   7 |     3/    3 batches | lr 0.00 | ms/batch 1448.92 | loss  0.76 | ppl     2.13\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 11.36s | valid loss  2.34 | valid ppl    10.41\n","-----------------------------------------------------------------------------------------\n","| epoch   8 |     1/    3 batches | lr 0.00 | ms/batch 5064.05 | loss  1.55 | ppl     4.73\n","| epoch   8 |     2/    3 batches | lr 0.00 | ms/batch 2532.45 | loss  0.97 | ppl     2.64\n","| epoch   8 |     3/    3 batches | lr 0.00 | ms/batch 1448.41 | loss  0.78 | ppl     2.18\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 10.02s | valid loss  2.27 | valid ppl     9.69\n","-----------------------------------------------------------------------------------------\n","| epoch   9 |     1/    3 batches | lr 0.00 | ms/batch 5052.30 | loss  1.47 | ppl     4.34\n","| epoch   9 |     2/    3 batches | lr 0.00 | ms/batch 2460.77 | loss  0.89 | ppl     2.42\n","| epoch   9 |     3/    3 batches | lr 0.00 | ms/batch 1418.66 | loss  0.71 | ppl     2.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time:  9.91s | valid loss  2.18 | valid ppl     8.82\n","-----------------------------------------------------------------------------------------\n","| epoch  10 |     1/    3 batches | lr 0.00 | ms/batch 5034.79 | loss  1.44 | ppl     4.23\n","| epoch  10 |     2/    3 batches | lr 0.00 | ms/batch 2510.44 | loss  0.88 | ppl     2.41\n","| epoch  10 |     3/    3 batches | lr 0.00 | ms/batch 1474.03 | loss  0.73 | ppl     2.07\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time:  9.99s | valid loss  2.27 | valid ppl     9.66\n","-----------------------------------------------------------------------------------------\n"]}],"source":["best_val_loss = float(\"inf\")\n","epochs = 10 # The number of epochs\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train()\n","    val_loss = evaluate(model, val_data, val_target)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                     val_loss, math.exp(val_loss)))\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step()"]},{"cell_type":"code","execution_count":null,"id":"atlantic-abortion","metadata":{"id":"atlantic-abortion","executionInfo":{"status":"ok","timestamp":1655216471784,"user_tz":-120,"elapsed":974,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a9a113c-b922-4027-fbc4-8f50e39c6e62"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","| End of training | test loss  2.15 | test ppl     8.56\n","=========================================================================================\n"]}],"source":["test_loss = evaluate(best_model, test_data, test_target)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"]},{"cell_type":"code","source":["# Just to stop the execution if execute all\n","# br"],"metadata":{"id":"FDc9pjvfcAHt"},"id":"FDc9pjvfcAHt","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tensor_to_tokens(my_tensor):\n","  \"\"\"Converts the output tensor holding the holds embedding to the holds word\"\"\"\n","  x = [int(t) for t in my_tensor]\n","  return [inverse_token_vocabulary[t] for t in x]"],"metadata":{"id":"DAxiF9IU5h0u"},"id":"DAxiF9IU5h0u","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ultimate-saver","metadata":{"id":"ultimate-saver"},"outputs":[],"source":["def write_sentence(xx):\n","    sentence = \"\"\n","    for word in tensor_to_tokens(xx.reshape(-1)):\n","        sentence+= word +\" \"\n","    print(sentence)\n","    \n","def complete_sentence(xx, length, src_mask):\n","    sentence = \"\"\n","    # print(xx)\n","    # for word in tensor_to_tokens(xx[0,:,2]):\n","    #     sentence+= word +\" \"\n","    sentence += \"|\"\n","    # crete new tokens\n","    output_tensor = torch.zeros(MAX_LENGTH + length - 1)\n","    output_tensor[:MAX_LENGTH-1] = xx[0,1:MAX_LENGTH,2]\n","    for i in range(length):\n","        # Compute output of the model from the current sequence\n","        out = model(xx.to(device), src_mask)[0]\n","        # Take the label with max probability\n","        labels = torch.argmax(out, 1).view(-1)\n","        # Extract the corresponding token and append it to the sequence\n","        # IMPORTANT: we have to take the token corresponding to the actual hold, so the i-th member of the output\n","        # which is placed at the MAX_LENGTH + i index of the full concatenation\n","        idx_new_pred = MAX_LENGTH+i-1\n","        # print('idx', idx_new_pred)\n","        new_token = tensor_to_tokens(labels.reshape(-1))[idx_new_pred]\n","        # print('token', new_token)\n","        sentence += new_token + \" \"\n","\n","        # Now we want to update the current sequence by appending the information \n","        # corresponding to the computed token\n","\n","        # Compute the index of the corresponding token in the input sequence\n","        output_tensor[idx_new_pred] = labels.reshape(-1)[idx_new_pred].item()\n","        index_xx_hold = torch.argwhere(xx[:,:,2] == labels.reshape(-1)[idx_new_pred].item())[0][-1]\n","        prediction = xx[:,index_xx_hold,:].reshape(1,1,3)\n","\n","        # We update the corresponding hold in the sentence\n","        if (xx.shape[1] > idx_new_pred + 1):\n","          xx[:, idx_new_pred+1, :] = prediction\n","          # print(xx)\n","          src_mask = model.generate_square_subsequent_mask(len(xx)).to(device)\n","    # print(sentence[sentence.find('|'):])\n","\n","    return sentence, output_tensor\n","    \n","    \n","# t = \"At the time of his marriage, William's father, John Yeats, was studying law, but would later pursue art studies at Heatherley School of Fine Art, in London. William's mother, Susan Mary Pollexfen, came from Sligo, from a wealthy merchant family, which owned a\"\n","# t = torch.tensor(vocab(tokenizer(t)))\n","# src_mask = model.generate_square_subsequent_mask(len(t)).to(device)\n","# t = t.reshape([-1, 1]).to(device)\n","\n","# complete_sentence(t, 100, src_mask)  "]},{"cell_type":"code","source":["idx_to_check = range(100,120)\n","for i in idx_to_check:\n","  t = input[i].view(1, input.shape[1],-1)\n","  t_input = t.clone()\n","  t_input[:,MAX_LENGTH:,:] = t_input[:,0,:].repeat(1,MAX_LENGTH-1,1) # Replace last parts of the input with garbage, it is anyway not used at inference\n","  src_mask = model.generate_square_subsequent_mask(len(t_input)).to(device)\n","  t_input = t_input.to(device)\n","\n","  sentence, output_tensor = complete_sentence(t_input, MAX_LENGTH, src_mask) \n","  print(\"=================================================================\")\n","  print(f\"Checking sequence {i}\")\n","  print('OUTPUT:', output_tensor[MAX_LENGTH-1:])\n","  print('TARGET:', outputs_tokens[i][MAX_LENGTH-1:])\n","# print(t_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DTuLz-_jkIU","executionInfo":{"status":"ok","timestamp":1655216529908,"user_tz":-120,"elapsed":6126,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"outputId":"03050d12-760b-483c-b8c7-e0803dfce5f3"},"id":"0DTuLz-_jkIU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=================================================================\n","Checking sequence 100\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([12.,  0.,  7.,  4., 11.,  8., 10.,  5.,  9.,  3.,  1.,  2.,  6., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 101\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([11.,  1.,  7.,  4.,  6.,  5., 12., 10.,  0.,  9.,  2.,  8.,  3., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 102\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 9.,  2., 10.,  6., 12.,  4.,  0.,  8.,  5., 11.,  7.,  3.,  1., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 103\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 7.,  4.,  1.,  0., 11.,  9.,  2.,  6.,  3.,  8., 12., 10.,  5., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 104\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 5.,  7.,  3.,  4.,  6., 10.,  8.,  2.,  0., 12.,  1., 11.,  9., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 105\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([11.,  2.,  8.,  1.,  0.,  5.,  9.,  6.,  7.,  3., 10., 12.,  4., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 106\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 6.,  7., 12., 11., 10.,  4.,  8.,  2.,  0.,  5.,  9.,  3.,  1., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 107\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 1., 12.,  3.,  7.,  6.,  4.,  0.,  2.,  8.,  5., 11., 10.,  9., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 108\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([10., 12.,  3.,  0., 11.,  8.,  1.,  6.,  5.,  7.,  9.,  4.,  2., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 109\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 5.,  8.,  4.,  3.,  1.,  0.,  7., 10.,  9.,  2., 12.,  6., 11., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 110\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 0.,  4., 11.,  3.,  9., 12., 10.,  2.,  5.,  1.,  6.,  8.,  7., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 111\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 9.,  7.,  5., 12.,  2.,  4., 10.,  3., 11.,  1.,  6.,  0.,  8., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 112\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 6.,  9., 10., 12.,  2.,  3.,  7.,  8.,  1., 11.,  5.,  4.,  0., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 113\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 2.,  8.,  3.,  5.,  7., 12., 11.,  1.,  6.,  4.,  9.,  0., 10., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 114\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 0.,  1.,  4., 11.,  5.,  9.,  2.,  3.,  6.,  8.,  7., 10., 12., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 115\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 4.,  1.,  7.,  9.,  3., 11., 12.,  6., 10.,  0.,  8.,  2.,  5., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 116\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 6.,  3.,  5.,  1.,  7.,  0., 10.,  4., 11., 12.,  9.,  2.,  8., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 117\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 0.,  7., 11.,  5.,  2., 10.,  3.,  9., 12.,  4.,  1.,  8.,  6., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 118\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([12., 10.,  9.,  4.,  5.,  0.,  6., 11.,  2.,  8.,  3.,  7.,  1., 13.,\n","        14., 14., 14., 14., 14., 14.])\n","=================================================================\n","Checking sequence 119\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,\n","        7., 7.])\n","TARGET: tensor([ 0.,  4.,  2.,  5., 11.,  1., 10., 12.,  9.,  3.,  7.,  8.,  6., 13.,\n","        14., 14., 14., 14., 14., 14.])\n"]}]},{"cell_type":"code","execution_count":null,"id":"understood-storm","metadata":{"id":"understood-storm"},"outputs":[],"source":["# idx_to_check = 869\n","# t = input[idx_to_check].view(1, input.shape[1],-1)\n","# t_input = t.clone()\n","# # t_input[:,MAX_LENGTH:,:] = t_input[:,0,:].repeat(1,MAX_LENGTH-1,1)\n","# print(t_input)"]},{"cell_type":"code","source":["# src_mask = model.generate_square_subsequent_mask(len(t_input)).to(device)\n","# t_input = t_input.to(device)\n","\n","# sentence = complete_sentence(t_input, 60, src_mask) "],"metadata":{"id":"3b5x4-426nKA"},"id":"3b5x4-426nKA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outputs_tokens[idx_to_check]"],"metadata":{"id":"2mJA6Bi7UtQZ"},"id":"2mJA6Bi7UtQZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"e3KL2sibUujl"},"id":"e3KL2sibUujl","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Transformer_reworked.ipynb","provenance":[],"collapsed_sections":["yFfiTLn4UPu3"]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}