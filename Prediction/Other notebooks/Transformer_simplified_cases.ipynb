{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import auth\n","auth.authenticate_user()\n","import gspread\n","from google.auth import default\n","creds, _ = default()\n","\n","gc = gspread.authorize(creds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL4ELfZp33qP","executionInfo":{"status":"ok","timestamp":1654867048597,"user_tz":-120,"elapsed":4134,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"outputId":"6b78db20-316a-4c6e-ccd4-227b7fd68a78"},"id":"RL4ELfZp33qP","execution_count":225,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install torchdata"],"metadata":{"id":"1V1qLQNh4IKg","executionInfo":{"status":"ok","timestamp":1654867051311,"user_tz":-120,"elapsed":2720,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8f97dfb-6b4a-4b4d-80bf-fced88e9067c"},"id":"1V1qLQNh4IKg","execution_count":226,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n"]}]},{"cell_type":"markdown","source":["## Previous Transformer"],"metadata":{"id":"yFfiTLn4UPu3"},"id":"yFfiTLn4UPu3"},{"cell_type":"code","execution_count":227,"id":"impaired-purpose","metadata":{"id":"impaired-purpose","executionInfo":{"status":"ok","timestamp":1654867051311,"user_tz":-120,"elapsed":59,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"outputs":[],"source":["import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, src_mask):\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output"]},{"cell_type":"code","execution_count":228,"id":"several-brazilian","metadata":{"id":"several-brazilian","executionInfo":{"status":"ok","timestamp":1654867051312,"user_tz":-120,"elapsed":59,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"markdown","source":["# Get the data: we work with random x-y coordinates with fixed length sequences"],"metadata":{"id":"RA9rqKhC4TGI"},"id":"RA9rqKhC4TGI"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import json\n","import itertools\n"],"metadata":{"id":"PaBe3iLH4Zdo","executionInfo":{"status":"ok","timestamp":1654867051312,"user_tz":-120,"elapsed":58,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"PaBe3iLH4Zdo","execution_count":229,"outputs":[]},{"cell_type":"markdown","source":["### Test with one sequence"],"metadata":{"id":"9NhH6rtRCPb-"},"id":"9NhH6rtRCPb-"},{"cell_type":"code","source":["LENGTH = 10\n","nb_decimals = 2\n","\n","target_coords = torch.round((torch.rand((LENGTH, 2))), decimals=nb_decimals) * 10**nb_decimals\n","target_coords[target_coords == 100.] = 99.\n","target_coords = target_coords[target_coords[:, 0].sort()[1]]"],"metadata":{"id":"T89LpkVQ4f23","executionInfo":{"status":"ok","timestamp":1654867051313,"user_tz":-120,"elapsed":58,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"T89LpkVQ4f23","execution_count":230,"outputs":[]},{"cell_type":"markdown","source":["We define a position vocabulary for the discretized coordinates"],"metadata":{"id":"dpIFxBrrJHmq"},"id":"dpIFxBrrJHmq"},{"cell_type":"code","source":["position_vocabulary = {i/(10**nb_decimals) : i for i in range(10**nb_decimals)}\n","position_vocabulary[-1] = 10**nb_decimals"],"metadata":{"id":"vOMRXxh5JPkZ","executionInfo":{"status":"ok","timestamp":1654867051313,"user_tz":-120,"elapsed":57,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"vOMRXxh5JPkZ","execution_count":231,"outputs":[]},{"cell_type":"markdown","source":["Now we generate permutations of the target sequence to get the input sequences. We also generate the token sequence (0,1,2...), which will be shuffled accordingly to get the target output sequence. We also generate the trivial token vocabulary"],"metadata":{"id":"eJIQGhBXE51c"},"id":"eJIQGhBXE51c"},{"cell_type":"code","source":["MAX_LENGTH = LENGTH\n","def generate_token_sequences(nb_seqs, length = MAX_LENGTH):\n","  token_sequence = torch.linspace(0,length-1, length, dtype=torch.int64)\n","  return token_sequence.repeat(nb_seqs, 1)\n","\n","token_vocabulary = {f'hold_{i}' : i for i in range(MAX_LENGTH + 1)} # the last one is the additional token that will be used for padding\n","inverse_token_vocabulary = {i: f'hold_{i}' for i in range(MAX_LENGTH + 1)}"],"metadata":{"id":"9P5l84SFPgzJ","executionInfo":{"status":"ok","timestamp":1654867051313,"user_tz":-120,"elapsed":57,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"9P5l84SFPgzJ","execution_count":232,"outputs":[]},{"cell_type":"code","source":["# From the target sequence, generate random holds sequence for input \n","def generate_input_sequences(target, nb_perms = 2):\n","  input_seqs = []\n","  output_seqs = []\n","  input_token_seqs = generate_token_sequences(nb_seqs = nb_perms, length = target.shape[0])\n","  output_token_seqs = []\n","  for n in range(nb_perms):\n","    full_input = torch.cat((target, input_token_seqs[n].view(-1,1)),1)\n","    shuffled_input = np.random.permutation(full_input)\n","\n","    input_seqs.append((torch.Tensor(shuffled_input[:,:2])))\n","    output_token_seqs.append(torch.Tensor(shuffled_input[:,2:]).view(-1))\n","    output_seqs.append(target)\n","    \n","\n","  return input_seqs, output_seqs, torch.vstack(output_token_seqs)\n","\n","input_seqs, output_seqs, output_token_seqs = generate_input_sequences(target_coords)"],"metadata":{"id":"G1u1SaoH9czb","executionInfo":{"status":"ok","timestamp":1654867051314,"user_tz":-120,"elapsed":57,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"G1u1SaoH9czb","execution_count":233,"outputs":[]},{"cell_type":"code","source":["print(input_seqs)\n","print(output_seqs)\n","print(output_token_seqs)"],"metadata":{"id":"tLI04l18PdL8","executionInfo":{"status":"ok","timestamp":1654867051315,"user_tz":-120,"elapsed":57,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8769b0cd-1d8e-4741-901c-e81474a59ccc"},"id":"tLI04l18PdL8","execution_count":234,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[90.0000, 75.0000],\n","        [39.0000, 80.0000],\n","        [24.0000, 89.0000],\n","        [19.0000, 42.0000],\n","        [59.0000, 65.0000],\n","        [53.0000, 34.0000],\n","        [55.0000, 35.0000],\n","        [73.0000, 13.0000],\n","        [ 5.0000, 75.0000],\n","        [53.0000, 90.0000]]), tensor([[73.0000, 13.0000],\n","        [53.0000, 90.0000],\n","        [59.0000, 65.0000],\n","        [55.0000, 35.0000],\n","        [ 5.0000, 75.0000],\n","        [19.0000, 42.0000],\n","        [39.0000, 80.0000],\n","        [90.0000, 75.0000],\n","        [24.0000, 89.0000],\n","        [53.0000, 34.0000]])]\n","[tensor([[ 5.0000, 75.0000],\n","        [19.0000, 42.0000],\n","        [24.0000, 89.0000],\n","        [39.0000, 80.0000],\n","        [53.0000, 90.0000],\n","        [53.0000, 34.0000],\n","        [55.0000, 35.0000],\n","        [59.0000, 65.0000],\n","        [73.0000, 13.0000],\n","        [90.0000, 75.0000]]), tensor([[ 5.0000, 75.0000],\n","        [19.0000, 42.0000],\n","        [24.0000, 89.0000],\n","        [39.0000, 80.0000],\n","        [53.0000, 90.0000],\n","        [53.0000, 34.0000],\n","        [55.0000, 35.0000],\n","        [59.0000, 65.0000],\n","        [73.0000, 13.0000],\n","        [90.0000, 75.0000]])]\n","tensor([[9., 3., 2., 1., 7., 5., 6., 8., 0., 4.],\n","        [8., 4., 7., 6., 0., 1., 3., 9., 2., 5.]])\n"]}]},{"cell_type":"markdown","source":["Finally, we have to pad the sequences"],"metadata":{"id":"JGMRrhfqHFpI"},"id":"JGMRrhfqHFpI"},{"cell_type":"code","source":["# We define a function to generate a dummy input sequence of length MAX_LENGTH\n","# def generate_dummy_sequence(dummy_char = -1):\n","#   return torch.full((MAX_LENGTH, 2), fill_value = dummy_char)\n","\n","# dummy_seq = generate_dummy_sequence()\n","# outputs = output_seqs + [dummy_seq]\n","# inputs = input_seqs + [dummy_seq]"],"metadata":{"id":"AjI0I8T5IVhU","executionInfo":{"status":"ok","timestamp":1654867051316,"user_tz":-120,"elapsed":52,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"AjI0I8T5IVhU","execution_count":235,"outputs":[]},{"cell_type":"code","source":["# Now we use this function to pad the coordinates sequences\n","# inputs_coords = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=position_vocabulary[-1])\n","# outputs_coords = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=position_vocabulary[-1])\n","inputs_coords = torch.stack(input_seqs)\n","outputs_coords = torch.stack(output_seqs)"],"metadata":{"id":"Qvj42rJzHy8O","executionInfo":{"status":"ok","timestamp":1654867051316,"user_tz":-120,"elapsed":51,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"Qvj42rJzHy8O","execution_count":236,"outputs":[]},{"cell_type":"code","source":["# To get the full input token sequences, we just generate them with length = MAX_LENGTH\n","inputs_token_seqs = generate_token_sequences(nb_seqs = inputs_coords.shape[0], length = MAX_LENGTH)\n","# inputs_token_seqs[:,output_token_seqs.shape[1]:] = MAX_LENGTH\n","# To get the full target token sequences, we take the input ones and replace the first part (non padded) by the target sequences previously generated"],"metadata":{"id":"FWvVaRWLCV-X","executionInfo":{"status":"ok","timestamp":1654867051316,"user_tz":-120,"elapsed":50,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"FWvVaRWLCV-X","execution_count":237,"outputs":[]},{"cell_type":"code","source":["inputs_coords"],"metadata":{"id":"7rhJXPsTFWzS","executionInfo":{"status":"ok","timestamp":1654867051317,"user_tz":-120,"elapsed":50,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"328a4f17-4c08-434a-e99a-03377fc1d691"},"id":"7rhJXPsTFWzS","execution_count":238,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[90.0000, 75.0000],\n","         [39.0000, 80.0000],\n","         [24.0000, 89.0000],\n","         [19.0000, 42.0000],\n","         [59.0000, 65.0000],\n","         [53.0000, 34.0000],\n","         [55.0000, 35.0000],\n","         [73.0000, 13.0000],\n","         [ 5.0000, 75.0000],\n","         [53.0000, 90.0000]],\n","\n","        [[73.0000, 13.0000],\n","         [53.0000, 90.0000],\n","         [59.0000, 65.0000],\n","         [55.0000, 35.0000],\n","         [ 5.0000, 75.0000],\n","         [19.0000, 42.0000],\n","         [39.0000, 80.0000],\n","         [90.0000, 75.0000],\n","         [24.0000, 89.0000],\n","         [53.0000, 34.0000]]])"]},"metadata":{},"execution_count":238}]},{"cell_type":"code","source":["outputs_coords"],"metadata":{"id":"c6_ynnjaFZeJ","executionInfo":{"status":"ok","timestamp":1654867051317,"user_tz":-120,"elapsed":45,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6fb9b5c-a1bd-4e30-edd5-0527e03ae5c2"},"id":"c6_ynnjaFZeJ","execution_count":239,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 5.0000, 75.0000],\n","         [19.0000, 42.0000],\n","         [24.0000, 89.0000],\n","         [39.0000, 80.0000],\n","         [53.0000, 90.0000],\n","         [53.0000, 34.0000],\n","         [55.0000, 35.0000],\n","         [59.0000, 65.0000],\n","         [73.0000, 13.0000],\n","         [90.0000, 75.0000]],\n","\n","        [[ 5.0000, 75.0000],\n","         [19.0000, 42.0000],\n","         [24.0000, 89.0000],\n","         [39.0000, 80.0000],\n","         [53.0000, 90.0000],\n","         [53.0000, 34.0000],\n","         [55.0000, 35.0000],\n","         [59.0000, 65.0000],\n","         [73.0000, 13.0000],\n","         [90.0000, 75.0000]]])"]},"metadata":{},"execution_count":239}]},{"cell_type":"code","source":["inputs_token_seqs"],"metadata":{"id":"pL6hT7FBFfqp","executionInfo":{"status":"ok","timestamp":1654867051317,"user_tz":-120,"elapsed":41,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f722d39-70b9-4a8c-b458-33e4f36792f0"},"id":"pL6hT7FBFfqp","execution_count":240,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n","        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"]},"metadata":{},"execution_count":240}]},{"cell_type":"code","source":["output_token_seqs"],"metadata":{"id":"39UbzyfiFiPS","executionInfo":{"status":"ok","timestamp":1654867051317,"user_tz":-120,"elapsed":37,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d65658d0-1703-4b85-ecf5-c9f409ec6da4"},"id":"39UbzyfiFiPS","execution_count":241,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[9., 3., 2., 1., 7., 5., 6., 8., 0., 4.],\n","        [8., 4., 7., 6., 0., 1., 3., 9., 2., 5.]])"]},"metadata":{},"execution_count":241}]},{"cell_type":"markdown","source":["We now have 4 list:\n","- output_seqs (nb_perms, len(sequence), 2) containing the coordinates and the limbs of the target holds sequence, ordered, repeated nb_perms times\n","- input_seqs (nb_perms, len(sequence), 2), same, but the nb_perms objects are permuted version of the target sequence\n","- input_token_seqs (nb_perms, len(sequence)) containing the numbers from 0 to len(sequence) - 1, representing the holds in the input sequence\n","- output_token_seqs (nb_perms, len(sequence)), same, but they are permuted in the same way as the coordinates, so that we have the actual target sequence to look for"],"metadata":{"id":"r3UaMoP_F2QQ"},"id":"r3UaMoP_F2QQ"},{"cell_type":"code","source":["print(inputs_token_seqs.shape)"],"metadata":{"id":"n3tSHx5FFxRL","executionInfo":{"status":"ok","timestamp":1654867051318,"user_tz":-120,"elapsed":34,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e26177bf-6d0b-4020-c8dc-f7333e368795"},"id":"n3tSHx5FFxRL","execution_count":242,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 10])\n"]}]},{"cell_type":"code","source":["outputs_token_seqs = inputs_token_seqs\n","outputs_token_seqs[:,:output_token_seqs.shape[1]] = output_token_seqs\n","print(outputs_token_seqs)"],"metadata":{"id":"tqbI7mv9F0Hq","executionInfo":{"status":"ok","timestamp":1654867051318,"user_tz":-120,"elapsed":32,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9345f16b-fc6c-4e79-9050-8fb963dda018"},"id":"tqbI7mv9F0Hq","execution_count":243,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9, 3, 2, 1, 7, 5, 6, 8, 0, 4],\n","        [8, 4, 7, 6, 0, 1, 3, 9, 2, 5]])\n"]}]},{"cell_type":"markdown","source":["Now, in order to work (?), the Transformer should complete the sequences by looking at a concatenation of the inputs and outputs. We do so by obtaining 2 sequences of length 39, one made of the 20 inputs and first 19 outputs, this will be our INPUT. The other is made of the last 19 inputs and the 20 outputs, this is our OUTPUT."],"metadata":{"id":"PhtaQOW5JUnT"},"id":"PhtaQOW5JUnT"},{"cell_type":"code","source":["inputs_tokens_cat = torch.cat((inputs_token_seqs, outputs_token_seqs[:,:-1]), dim=1)\n","outputs_tokens_cat = torch.cat((inputs_token_seqs[:,1:], outputs_token_seqs), dim=1)\n","inputs_coords_cat = torch.cat((inputs_coords, outputs_coords[:,:-1]), dim=1)\n","outputs_coords_cat = torch.cat((inputs_coords[:,1:], outputs_coords), dim=1)"],"metadata":{"id":"Ryy9sfQGBt_-","executionInfo":{"status":"ok","timestamp":1654867051318,"user_tz":-120,"elapsed":31,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"Ryy9sfQGBt_-","execution_count":244,"outputs":[]},{"cell_type":"markdown","source":["### Now that we have all of these functions, we can process the entire dataframe by reading the data for all sequences."],"metadata":{"id":"fGNYxOCOQ0CB"},"id":"fGNYxOCOQ0CB"},{"cell_type":"code","source":["def prepare_data(nb_seqs = 5, nb_perms = 30):\n","  \"\"\"Returns 2 lists of arrays containing all sequences of holds and moves for each climb\"\"\"\n","  input_seqs = []\n","  output_seqs = []\n","  output_token_seqs = []\n","\n","  inputs_tokens = torch.Tensor()\n","  outputs_tokens = torch.Tensor()\n","\n","  for i in range(nb_seqs):\n","      # Generate random coords and order the sequences based on their x coordinates\n","      target_coords = torch.round((torch.rand((LENGTH, 2))), decimals=nb_decimals) * 10**nb_decimals\n","      target_coords[target_coords == 100.] = 99.\n","      target_coords = target_coords[target_coords[:, 0].sort()[1]]\n","      \n","      input_seqs_video, output_seqs_video, output_token_seqs_video = generate_input_sequences(target_coords, nb_perms=nb_perms)\n","      input_seqs += input_seqs_video\n","      output_seqs += output_seqs_video\n","\n","      # Copy the shuffled token sequences and add them to the list\n","      input_token_seqs = generate_token_sequences(nb_perms)\n","      # input_token_seqs[:,output_token_seqs_video.shape[1]:] = MAX_LENGTH # the last ones are padded with the additional token\n","      outputs_token_seqs = torch.clone(input_token_seqs)\n","      outputs_token_seqs[:,:output_token_seqs_video.shape[1]] = output_token_seqs_video\n","\n","      inputs_tokens_cat = torch.cat((input_token_seqs, outputs_token_seqs[:,:-1]), dim=1)\n","      outputs_tokens_cat = torch.cat((input_token_seqs[:,1:], outputs_token_seqs), dim=1)\n","      \n","\n","      inputs_tokens = torch.cat((inputs_tokens, inputs_tokens_cat))\n","      outputs_tokens = torch.cat((outputs_tokens, outputs_tokens_cat))\n","\n","  # # Pad the sequences\n","  # dummy_seq = generate_dummy_sequence()\n","  # outputs = output_seqs\n","  # inputs = input_seqs\n","\n","  # inputs_coords = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=position_vocabulary[-1])\n","  # outputs_coords = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=position_vocabulary[-1])\n","\n","  inputs_coords = torch.stack(input_seqs)\n","  outputs_coords = torch.stack(output_seqs)\n","\n","\n","  # # Remove the dummy sequence\n","  # nb_seqs = inputs_coords.shape[0] - 1\n","  # inputs_coords = inputs_coords[:nb_seqs]\n","  # outputs_coords = outputs_coords[:nb_seqs]\n","\n","\n","  inputs_coords_cat = torch.cat((inputs_coords, outputs_coords[:,:-1]), dim=1)\n","  outputs_coords_cat = torch.cat((inputs_coords[:,1:], outputs_coords), dim=1)\n","\n","  return inputs_coords_cat, outputs_coords_cat, inputs_tokens, outputs_tokens\n","\n","inputs_coords, outputs_coords, inputs_tokens, outputs_tokens = prepare_data(nb_seqs = 70, nb_perms=8)\n","print(f'Prepared sequences of shape {inputs_coords.shape}')"],"metadata":{"id":"FKtekkZkQzUL","executionInfo":{"status":"ok","timestamp":1654867051318,"user_tz":-120,"elapsed":30,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dabbf0fd-9d8b-4411-a1a8-c5886a3c7f9d"},"id":"FKtekkZkQzUL","execution_count":245,"outputs":[{"output_type":"stream","name":"stdout","text":["Prepared sequences of shape torch.Size([560, 19, 2])\n"]}]},{"cell_type":"code","source":["print(inputs_coords.shape)\n","print(outputs_coords.shape)\n","print(inputs_tokens.shape)\n","print(outputs_tokens.shape)"],"metadata":{"id":"9Q0oxPWYN07z","executionInfo":{"status":"ok","timestamp":1654867051319,"user_tz":-120,"elapsed":29,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3547f2a1-ff29-4e1f-9e0e-1a89c35cb2a6"},"id":"9Q0oxPWYN07z","execution_count":246,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([560, 19, 2])\n","torch.Size([560, 19, 2])\n","torch.Size([560, 19])\n","torch.Size([560, 19])\n"]}]},{"cell_type":"code","source":["inputs_coords[1]"],"metadata":{"id":"xB7gy7NI6Zja","executionInfo":{"status":"ok","timestamp":1654867051319,"user_tz":-120,"elapsed":28,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"50451454-b671-455e-f049-dc0b04708bb3"},"id":"xB7gy7NI6Zja","execution_count":247,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[80., 28.],\n","        [62., 67.],\n","        [99., 82.],\n","        [49., 61.],\n","        [19., 67.],\n","        [34., 11.],\n","        [56., 88.],\n","        [96., 81.],\n","        [62., 86.],\n","        [69., 23.],\n","        [19., 67.],\n","        [34., 11.],\n","        [49., 61.],\n","        [56., 88.],\n","        [62., 67.],\n","        [62., 86.],\n","        [69., 23.],\n","        [80., 28.],\n","        [96., 81.]])"]},"metadata":{},"execution_count":247}]},{"cell_type":"code","source":["inputs_tokens[1]"],"metadata":{"id":"M_losO9z6g1Z","executionInfo":{"status":"ok","timestamp":1654867051319,"user_tz":-120,"elapsed":26,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fcd5e3ba-df22-4215-a5e1-e9f6e1c57a7e"},"id":"M_losO9z6g1Z","execution_count":248,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 7., 4., 9., 2., 0., 1., 3., 8.,\n","        5.])"]},"metadata":{},"execution_count":248}]},{"cell_type":"code","source":["outputs_coords[1]"],"metadata":{"id":"QYA6A29OgSjd","executionInfo":{"status":"ok","timestamp":1654867051319,"user_tz":-120,"elapsed":22,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1127e416-60ae-4ac5-c700-6f33847bb2d6"},"id":"QYA6A29OgSjd","execution_count":249,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[62., 67.],\n","        [99., 82.],\n","        [49., 61.],\n","        [19., 67.],\n","        [34., 11.],\n","        [56., 88.],\n","        [96., 81.],\n","        [62., 86.],\n","        [69., 23.],\n","        [19., 67.],\n","        [34., 11.],\n","        [49., 61.],\n","        [56., 88.],\n","        [62., 67.],\n","        [62., 86.],\n","        [69., 23.],\n","        [80., 28.],\n","        [96., 81.],\n","        [99., 82.]])"]},"metadata":{},"execution_count":249}]},{"cell_type":"code","source":["outputs_tokens[1]"],"metadata":{"id":"X07PBd5j7R8m","executionInfo":{"status":"ok","timestamp":1654867051320,"user_tz":-120,"elapsed":22,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b3cdbca-c7d6-4978-c64b-dbcf48609f95"},"id":"X07PBd5j7R8m","execution_count":250,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 7., 4., 9., 2., 0., 1., 3., 8., 5.,\n","        6.])"]},"metadata":{},"execution_count":250}]},{"cell_type":"markdown","source":["Finally we concatenate all the data to create the input and target tensors"],"metadata":{"id":"tDgpGJPQWIhe"},"id":"tDgpGJPQWIhe"},{"cell_type":"code","source":["sequence_length = 2 * MAX_LENGTH - 1\n","input = torch.cat((inputs_coords, inputs_tokens.view(-1, sequence_length, 1)), 2)\n","target = outputs_tokens.view(-1)"],"metadata":{"id":"DfvGjt2gV-uH","executionInfo":{"status":"ok","timestamp":1654867051320,"user_tz":-120,"elapsed":20,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"DfvGjt2gV-uH","execution_count":251,"outputs":[]},{"cell_type":"code","source":["print(input.shape)\n","print(target.shape)"],"metadata":{"id":"XAxk7iyaXc2B","executionInfo":{"status":"ok","timestamp":1654867051320,"user_tz":-120,"elapsed":20,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f3ddab8-c3d3-49be-f99f-8a653e7d7587"},"id":"XAxk7iyaXc2B","execution_count":252,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([560, 19, 3])\n","torch.Size([10640])\n"]}]},{"cell_type":"markdown","source":["# At that point, we have all the input and output sequences prepared, both for coordinates and tokens. We now have to feed them into the Transformer."],"metadata":{"id":"rRkgb1m9WpyI"},"id":"rRkgb1m9WpyI"},{"cell_type":"markdown","source":["First, we adapt the position embedding to work with our data format"],"metadata":{"id":"28hM85bKVJ9A"},"id":"28hM85bKVJ9A"},{"cell_type":"code","source":["class PositionalEncoding_modified(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len = 5000):\n","        super(PositionalEncoding_modified, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.d_model = d_model\n","\n","\n","    def pe(self, position):\n","        pe = torch.zeros(position.shape[0], position.shape[1], self.d_model).to(device)\n","        \n","        # # Test by adding and scaling the 2 coords by div_term --> NOT GOOD\n","        # div_term = (torch.exp(torch.arange(0, self.d_model).float() * (-math.log(10000.0) / self.d_model))).view(1,-1).repeat(2,1).to(device)\n","\n","        # # Multiply by div_term for later\n","        # position_scaled = position @ div_term\n","\n","        # pe[:, :, 0::2] = torch.sin(position_scaled[:,:,0::2]) \n","        # pe[:, :, 1::2] = torch.cos(position_scaled[:,:,1::2])\n","\n","        # # Just embedd the x-coordinate\n","        div_term_half = (torch.exp(torch.arange(0, self.d_model,2).float() * (-math.log(10000.0) / self.d_model))).view(1,-1).to(device)\n","        div_term = torch.empty(self.d_model).view(1,-1)\n","        div_term[:,0::2] = div_term_half\n","        div_term[:,1::2] = div_term_half\n","\n","        pos_x_scaled = position[:,:,0].view(position.shape[0], position.shape[1],1) @ div_term\n","        pos_y_scaled = position[:,:,1].view(position.shape[0], position.shape[1],1) @ div_term\n","\n","\n","        # Embed x\n","        pe[:, :, 0::2] = torch.sin(pos_x_scaled[:,:,0::2]) \n","        pe[:, :, 1::2] = torch.cos(pos_x_scaled[:,:,1::2]) \n","\n","        return pe\n","\n","\n","    def forward(self, x_encoded, coords):\n","        pos_emb = self.pe(coords)\n","        y = x_encoded + pos_emb\n","        # y =  self.pe(x[:,:,:2] )\n","        return self.dropout(y)"],"metadata":{"id":"xQwR4-5dVWCA","executionInfo":{"status":"ok","timestamp":1654867051320,"user_tz":-120,"elapsed":18,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"xQwR4-5dVWCA","execution_count":253,"outputs":[]},{"cell_type":"code","source":["# Test the position embedding with no token embedding for now (keeping the 30 holds sequence)\n","# x = input[0].view(1,9,3).to(device)\n","# # print(x)\n","# pos_model = PositionalEncoding_modified(MAX_LENGTH)\n","# pos_emb = pos_model(x[:,:,2], x[:,:,:2])\n","# pos_emb"],"metadata":{"id":"QijyqCKdViZm","executionInfo":{"status":"ok","timestamp":1654867051320,"user_tz":-120,"elapsed":18,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"QijyqCKdViZm","execution_count":254,"outputs":[]},{"cell_type":"code","source":["class TransformerModel_modified(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel_modified, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding_modified(ninp, dropout)\n","        self.regular_pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken)\n","\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, src_mask):\n","        src_encoded = self.encoder(src[:,:,2].int()) * math.sqrt(self.ninp)\n","        #Position embedding based on the coordinates\n","        src = self.pos_encoder(src_encoded, src[:,:,:2])\n","        #Add also regular position embedding\n","        # src = self.regular_pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output"],"metadata":{"id":"6CWAn2cBbSpK","executionInfo":{"status":"ok","timestamp":1654867051853,"user_tz":-120,"elapsed":550,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"6CWAn2cBbSpK","execution_count":255,"outputs":[]},{"cell_type":"markdown","source":["Actual use of the transformer"],"metadata":{"id":"zOp-Q8nCVW6e"},"id":"zOp-Q8nCVW6e"},{"cell_type":"code","source":["train_per, val_per = 0.6, 0.2\n","train_size = int(train_per * input.shape[0])\n","target_train_size= train_size * input.shape[1]\n","val_size = int(val_per * input.shape[0])\n","target_val_size= val_size * input.shape[1]\n","\n","device = torch.device(\"cpu\")\n","train_data = input[:train_size].to(device)\n","train_target = target[:target_train_size].to(device)\n","val_data = input[train_size: train_size + val_size].to(device)\n","val_target = target[target_train_size: target_train_size + target_val_size].to(device)\n","test_data = input[train_size + val_size:].to(device)\n","test_target = target[target_train_size + target_val_size:].to(device)"],"metadata":{"id":"PXo_vQzrYlKo","executionInfo":{"status":"ok","timestamp":1654867051853,"user_tz":-120,"elapsed":8,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"PXo_vQzrYlKo","execution_count":256,"outputs":[]},{"cell_type":"code","source":["bptt = 100\n","def get_batch(input_source, target_source, i):\n","    i_target = input_source.shape[1] * i\n","    target_seq_len = min(bptt*input_source.shape[1], len(target_source) - input_source.shape[1] - i_target)\n","    seq_len = min(bptt, len(input_source) - 1 - i)\n","    data = input_source[i:i+seq_len]\n","    target = target_source[i_target:i_target+target_seq_len].long()\n","    return data, target\n","\n","data, targets = get_batch(train_data, train_target,  100)\n","print(data.shape, targets.shape)"],"metadata":{"id":"FsU8H1rNY8jS","executionInfo":{"status":"ok","timestamp":1654867051853,"user_tz":-120,"elapsed":7,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"219db235-9665-49ac-ae8c-e93f7213a834"},"id":"FsU8H1rNY8jS","execution_count":257,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 19, 3]) torch.Size([1900])\n"]}]},{"cell_type":"code","source":["ntokens = MAX_LENGTH + 1# the size of vocabulary\n","emsize = 512 # embedding dimension\n","nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","dropout = 0.2 # the dropout value\n","model = TransformerModel_modified(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"],"metadata":{"id":"oq8YbRSfYCeE","executionInfo":{"status":"ok","timestamp":1654867051854,"user_tz":-120,"elapsed":6,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"oq8YbRSfYCeE","execution_count":258,"outputs":[]},{"cell_type":"code","source":["bptt = 50\n","# Just a test to check the whole Transformer's application\n","src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","src, targets = get_batch(train_data, train_target, 0)\n","print(\"data \", data.shape)\n","src_encoded = model.encoder(src[:,:,2].int()) * math.sqrt(model.ninp)\n","print(\"encoded \", src_encoded.shape)\n","src = model.pos_encoder(src_encoded, src[:,:,:2])\n","output = model.transformer_encoder(src, src_mask)\n","output = model.decoder(output)"],"metadata":{"id":"VITHeczTYXub","executionInfo":{"status":"ok","timestamp":1654867051854,"user_tz":-120,"elapsed":6,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd2d9e87-f390-4732-e716-535f6a8b8a42"},"id":"VITHeczTYXub","execution_count":259,"outputs":[{"output_type":"stream","name":"stdout","text":["data  torch.Size([100, 19, 3])\n","encoded  torch.Size([50, 19, 512])\n"]}]},{"cell_type":"code","execution_count":260,"id":"durable-transport","metadata":{"id":"durable-transport","executionInfo":{"status":"ok","timestamp":1654867051854,"user_tz":-120,"elapsed":4,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"outputs":[],"source":["import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 4.5*10**-4 # learning rate\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.96), eps=10**(-8), weight_decay=4.5**-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train():\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, train_target, i)\n","        optimizer.zero_grad()\n","        if data.size(0) != bptt:\n","            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        log_interval = 1\n","        if batch % log_interval == 0 and batch > 0:\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n","                  'lr {:02.2f} | ms/batch {:5.2f} | '\n","                  'loss {:5.2f} | ppl {:8.2f}'.format(\n","                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n","                    elapsed * 1000 / log_interval,\n","                    cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(eval_model, data_source, target_source):\n","    eval_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, data_source.size(0) - 1, bptt):\n","            data, targets = get_batch(data_source, target_source, i)\n","            if data.size(0) != bptt:\n","                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n","            output = eval_model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += len(data) * criterion(output_flat, targets).item()\n","    return total_loss / (len(data_source) - 1)"]},{"cell_type":"code","execution_count":261,"id":"virgin-muscle","metadata":{"id":"virgin-muscle","executionInfo":{"status":"ok","timestamp":1654867071660,"user_tz":-120,"elapsed":19810,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6833673f-b830-41c2-e730-d9f0fea93dcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 |     1/    6 batches | lr 0.00 | ms/batch 1491.27 | loss  5.39 | ppl   219.88\n","| epoch   1 |     2/    6 batches | lr 0.00 | ms/batch 636.41 | loss  2.12 | ppl     8.31\n","| epoch   1 |     3/    6 batches | lr 0.00 | ms/batch 646.66 | loss  2.06 | ppl     7.88\n","| epoch   1 |     4/    6 batches | lr 0.00 | ms/batch 668.69 | loss  1.95 | ppl     7.02\n","| epoch   1 |     5/    6 batches | lr 0.00 | ms/batch 658.87 | loss  1.87 | ppl     6.48\n","| epoch   1 |     6/    6 batches | lr 0.00 | ms/batch 459.89 | loss  1.57 | ppl     4.82\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time:  4.99s | valid loss  1.45 | valid ppl     4.24\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |     1/    6 batches | lr 0.00 | ms/batch 1445.66 | loss  2.97 | ppl    19.58\n","| epoch   2 |     2/    6 batches | lr 0.00 | ms/batch 975.54 | loss  1.50 | ppl     4.49\n","| epoch   2 |     3/    6 batches | lr 0.00 | ms/batch 1090.03 | loss  1.43 | ppl     4.20\n","| epoch   2 |     4/    6 batches | lr 0.00 | ms/batch 1059.47 | loss  1.40 | ppl     4.06\n","| epoch   2 |     5/    6 batches | lr 0.00 | ms/batch 1093.53 | loss  1.36 | ppl     3.89\n","| epoch   2 |     6/    6 batches | lr 0.00 | ms/batch 926.86 | loss  1.40 | ppl     4.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time:  7.41s | valid loss  1.41 | valid ppl     4.11\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |     1/    6 batches | lr 0.00 | ms/batch 2707.29 | loss  2.71 | ppl    15.03\n","| epoch   3 |     2/    6 batches | lr 0.00 | ms/batch 1177.46 | loss  1.32 | ppl     3.73\n","| epoch   3 |     3/    6 batches | lr 0.00 | ms/batch 641.87 | loss  1.30 | ppl     3.67\n","| epoch   3 |     4/    6 batches | lr 0.00 | ms/batch 654.34 | loss  1.31 | ppl     3.72\n","| epoch   3 |     5/    6 batches | lr 0.00 | ms/batch 664.27 | loss  1.32 | ppl     3.75\n","| epoch   3 |     6/    6 batches | lr 0.00 | ms/batch 454.76 | loss  1.32 | ppl     3.75\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time:  6.77s | valid loss  1.30 | valid ppl     3.67\n","-----------------------------------------------------------------------------------------\n"]}],"source":["best_val_loss = float(\"inf\")\n","epochs = 3 # The number of epochs\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train()\n","    val_loss = evaluate(model, val_data, val_target)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                     val_loss, math.exp(val_loss)))\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","\n","    scheduler.step()"]},{"cell_type":"code","execution_count":262,"id":"atlantic-abortion","metadata":{"id":"atlantic-abortion","executionInfo":{"status":"ok","timestamp":1654867072182,"user_tz":-120,"elapsed":545,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f0b17dd-ed50-4b84-f722-77528ad50fa5"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","| End of training | test loss  1.30 | test ppl     3.68\n","=========================================================================================\n"]}],"source":["test_loss = evaluate(best_model, test_data, test_target)\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)"]},{"cell_type":"code","source":["# Just to stop the execution if execute all\n","# br"],"metadata":{"id":"FDc9pjvfcAHt","executionInfo":{"status":"ok","timestamp":1654867072183,"user_tz":-120,"elapsed":15,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"FDc9pjvfcAHt","execution_count":263,"outputs":[]},{"cell_type":"code","source":["def tensor_to_tokens(my_tensor):\n","  \"\"\"Converts the output tensor holding the holds embedding to the holds word\"\"\"\n","  x = [int(t) for t in my_tensor]\n","  return [inverse_token_vocabulary[t] for t in x]"],"metadata":{"id":"DAxiF9IU5h0u","executionInfo":{"status":"ok","timestamp":1654867072184,"user_tz":-120,"elapsed":15,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"DAxiF9IU5h0u","execution_count":264,"outputs":[]},{"cell_type":"code","execution_count":265,"id":"ultimate-saver","metadata":{"id":"ultimate-saver","executionInfo":{"status":"ok","timestamp":1654867072184,"user_tz":-120,"elapsed":14,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"outputs":[],"source":["def write_sentence(xx):\n","    sentence = \"\"\n","    for word in tensor_to_tokens(xx.reshape(-1)):\n","        sentence+= word +\" \"\n","    print(sentence)\n","    \n","def complete_sentence(xx, length, src_mask):\n","    sentence = \"\"\n","    # print(xx)\n","    # for word in tensor_to_tokens(xx[0,:,2]):\n","    #     sentence+= word +\" \"\n","    sentence += \"|\"\n","    # crete new tokens\n","    output_tensor = torch.zeros(MAX_LENGTH + length - 1)\n","    output_tensor[:MAX_LENGTH-1] = xx[0,1:MAX_LENGTH, 2]\n","\n","    for i in range(length):\n","        # Compute output of the model from the current sequence\n","        out = model(xx.to(device), src_mask)[0]\n","        # Take the label with max probability\n","        labels = torch.argmax(out, 1).view(-1)\n","        # Extract the corresponding token and append it to the sequence\n","        # IMPORTANT: we have to take the token corresponding to the actual hold, so the i-th member of the output\n","        # which is placed at the MAX_LENGTH + i index of the full concatenation\n","        idx_new_pred = MAX_LENGTH+i-1\n","        # print('idx', idx_new_pred)\n","        new_token = tensor_to_tokens(labels.reshape(-1))[idx_new_pred]\n","        # print('token', new_token)\n","        sentence += new_token + \" \"\n","\n","        # Now we want to update the current sequence by appending the information \n","        # corresponding to the computed token\n","\n","        # Compute the index of the corresponding token in the input sequence\n","        output_tensor[idx_new_pred] = labels.reshape(-1)[idx_new_pred].item()\n","        index_xx_hold = torch.argwhere(xx[:,:,2] == labels.reshape(-1)[idx_new_pred].item())[0][-1]\n","        prediction = xx[:,index_xx_hold,:].reshape(1,1,3)\n","\n","        # We update the corresponding hold in the sentence\n","        if (xx.shape[1] > idx_new_pred + 1):\n","          xx[:, idx_new_pred+1, :] = prediction\n","          # print(xx)\n","          src_mask = model.generate_square_subsequent_mask(len(xx)).to(device)\n","    \n","    # print(sentence[sentence.find('|'):])\n","\n","    return sentence, output_tensor\n","    \n","    \n","# t = \"At the time of his marriage, William's father, John Yeats, was studying law, but would later pursue art studies at Heatherley School of Fine Art, in London. William's mother, Susan Mary Pollexfen, came from Sligo, from a wealthy merchant family, which owned a\"\n","# t = torch.tensor(vocab(tokenizer(t)))\n","# src_mask = model.generate_square_subsequent_mask(len(t)).to(device)\n","# t = t.reshape([-1, 1]).to(device)\n","\n","# complete_sentence(t, 100, src_mask)  "]},{"cell_type":"code","execution_count":266,"id":"understood-storm","metadata":{"id":"understood-storm","executionInfo":{"status":"ok","timestamp":1654867073075,"user_tz":-120,"elapsed":905,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5b715c7-8d14-4da1-a2f8-214c57ecd150"},"outputs":[{"output_type":"stream","name":"stdout","text":["=================================================================\n","Checking sequence 45\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 7., 8., 9., 6., 7., 8., 9., 6.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 8., 2., 5., 7., 3., 1., 9., 4.,\n","        0.])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 560 + 1) instead\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"stream","name":"stdout","text":["=================================================================\n","Checking sequence 162\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 9., 2., 5., 4., 7., 8., 1., 0.,\n","        3.])\n","=================================================================\n","Checking sequence 468\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 7., 8., 9., 6., 7., 8., 9., 6.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 5., 0., 3., 8., 6., 2., 7., 9., 4.,\n","        1.])\n","=================================================================\n","Checking sequence 393\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 5., 0., 4., 3., 1., 9., 6., 2., 7.,\n","        8.])\n","=================================================================\n","Checking sequence 226\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 7., 8., 9., 7., 8., 9., 7., 8., 9.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 1., 8., 9., 6., 4., 5., 0., 7., 2.,\n","        3.])\n","=================================================================\n","Checking sequence 278\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 7., 8., 9., 6., 7., 8., 9., 6.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 8., 4., 9., 6., 7., 2., 5., 3., 0.,\n","        1.])\n","=================================================================\n","Checking sequence 62\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 4., 8., 3., 1., 6., 9., 5., 7.,\n","        2.])\n","=================================================================\n","Checking sequence 514\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 8., 9., 1., 2., 4., 7., 0., 3., 6.,\n","        5.])\n","=================================================================\n","Checking sequence 166\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 1., 4., 0., 5., 3., 7., 2., 9.,\n","        8.])\n","=================================================================\n","Checking sequence 149\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 7., 3., 4., 6., 9., 1., 2., 0., 5.,\n","        8.])\n","=================================================================\n","Checking sequence 211\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 7., 8., 9., 6., 7., 8., 9., 6.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 6., 4., 8., 5., 2., 1., 9., 7., 3.,\n","        0.])\n","=================================================================\n","Checking sequence 446\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 2., 0., 7., 8., 1., 6., 3., 9., 4.,\n","        5.])\n","=================================================================\n","Checking sequence 238\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 2., 4., 6., 7., 1., 8., 5., 9., 0.,\n","        3.])\n","=================================================================\n","Checking sequence 398\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 7., 8., 9., 7., 8., 9., 7., 8., 9.,\n","        7.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 8., 4., 1., 3., 7., 0., 9., 2., 5.,\n","        6.])\n","=================================================================\n","Checking sequence 63\n","OUTPUT: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8.,\n","        9.])\n","TARGET: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 4., 1., 0., 7., 2., 6., 3., 9., 8.,\n","        5.])\n"]}],"source":["idx_to_check = np.random.random_integers(0, input.shape[0], size=15)\n","for i in idx_to_check:\n","  t = input[i].view(1, input.shape[1],-1)\n","  t_input = t.clone()\n","  t_input[:,MAX_LENGTH:,:] = t_input[:,0,:].repeat(1,MAX_LENGTH-1,1) # Replace last parts of the input with garbage, it is anyway not used at inference\n","  src_mask = model.generate_square_subsequent_mask(len(t_input)).to(device)\n","  t_input = t_input.to(device)\n","\n","  sentence, output_tensor = complete_sentence(t_input, MAX_LENGTH, src_mask) \n","  print(\"=================================================================\")\n","  print(f\"Checking sequence {i}\")\n","  print('OUTPUT:', output_tensor)\n","  print('TARGET:', outputs_tokens[i])\n","# print(t_input)"]},{"cell_type":"code","source":[""],"metadata":{"id":"3b5x4-426nKA","executionInfo":{"status":"ok","timestamp":1654867073076,"user_tz":-120,"elapsed":10,"user":{"displayName":"Thomas Rimbot","userId":"00803464136383640136"}}},"id":"3b5x4-426nKA","execution_count":266,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Transformer_simplified_cases.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}