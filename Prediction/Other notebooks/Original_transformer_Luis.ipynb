{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arctic-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "def data_process(raw_text_iter):\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "        \n",
    "inv_map = {v: k for k, v in vocab.get_stoi().items()}\n",
    "\n",
    "def tensor_to_tokens(my_tensor):\n",
    "    x = [int(t) for t in my_tensor]\n",
    "    return [inv_map[t] for t in x]\n",
    "    \n",
    "\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attractive-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 20]) torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "bptt = 100\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "data, targets = get_batch(train_data, 0)\n",
    "print(data.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab) # the size of vocabulary\n",
    "emsize = 512 # embedding dimension\n",
    "nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "driving-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3869,    19,     1,  ...,  1687,    19, 25204],\n",
       "        [   21, 17322,  4347,  ...,    50, 14545,     2],\n",
       "        [  780, 10360,     4,  ...,     8,    26,     5],\n",
       "        ...,\n",
       "        [19009,    47,    11,  ...,     0,  2452, 16017],\n",
       "        [   56,    61,    15,  ...,     3,    41, 16805],\n",
       "        [    1,   619,     5,  ...,    43,    10,    16]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, targets = get_batch(train_data, i)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blond-tunisia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  torch.Size([100, 20])\n",
      "encoded  torch.Size([100, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "src, targets = get_batch(train_data, 0)\n",
    "print(\"data \", data.shape)\n",
    "src = model.encoder(src) * math.sqrt(model.ninp)\n",
    "print(\"encoded \", src.shape)\n",
    "src = model.pos_encoder(src)\n",
    "output = model.transformer_encoder(src, src_mask)\n",
    "output = model.decoder(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "durable-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 4.5*10**-4 # learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.96), eps=10**(-8), weight_decay=4.5**-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != bptt:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "virgin-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 1024 batches | lr 0.01 | ms/batch 37.63 | loss  7.01 | ppl  1107.98\n",
      "| epoch   1 |   400/ 1024 batches | lr 0.01 | ms/batch 39.40 | loss  6.92 | ppl  1015.60\n",
      "| epoch   1 |   600/ 1024 batches | lr 0.01 | ms/batch 38.23 | loss  6.91 | ppl  1006.70\n",
      "| epoch   1 |   800/ 1024 batches | lr 0.01 | ms/batch 37.99 | loss  6.89 | ppl   983.69\n",
      "| epoch   1 |  1000/ 1024 batches | lr 0.01 | ms/batch 39.69 | loss  6.87 | ppl   964.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 40.71s | valid loss  6.83 | valid ppl   925.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 1024 batches | lr 0.01 | ms/batch 37.82 | loss  6.75 | ppl   856.87\n",
      "| epoch   2 |   400/ 1024 batches | lr 0.01 | ms/batch 37.80 | loss  6.76 | ppl   860.73\n",
      "| epoch   2 |   600/ 1024 batches | lr 0.01 | ms/batch 38.35 | loss  6.75 | ppl   855.95\n",
      "| epoch   2 |   800/ 1024 batches | lr 0.01 | ms/batch 38.78 | loss  6.73 | ppl   835.05\n",
      "| epoch   2 |  1000/ 1024 batches | lr 0.01 | ms/batch 40.01 | loss  6.71 | ppl   817.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 40.67s | valid loss  6.94 | valid ppl  1030.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 1024 batches | lr 0.01 | ms/batch 38.08 | loss  6.77 | ppl   869.63\n",
      "| epoch   3 |   400/ 1024 batches | lr 0.01 | ms/batch 39.10 | loss  6.75 | ppl   857.27\n",
      "| epoch   3 |   600/ 1024 batches | lr 0.01 | ms/batch 39.69 | loss  6.76 | ppl   858.65\n",
      "| epoch   3 |   800/ 1024 batches | lr 0.01 | ms/batch 39.79 | loss  6.73 | ppl   835.70\n",
      "| epoch   3 |  1000/ 1024 batches | lr 0.01 | ms/batch 37.39 | loss  6.71 | ppl   817.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 40.94s | valid loss  6.96 | valid ppl  1058.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   200/ 1024 batches | lr 0.01 | ms/batch 38.92 | loss  6.72 | ppl   828.90\n",
      "| epoch   4 |   400/ 1024 batches | lr 0.01 | ms/batch 38.86 | loss  6.72 | ppl   831.03\n",
      "| epoch   4 |   600/ 1024 batches | lr 0.01 | ms/batch 39.01 | loss  6.73 | ppl   839.57\n",
      "| epoch   4 |   800/ 1024 batches | lr 0.01 | ms/batch 38.20 | loss  6.71 | ppl   823.54\n",
      "| epoch   4 |  1000/ 1024 batches | lr 0.01 | ms/batch 39.67 | loss  6.69 | ppl   805.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 41.07s | valid loss  7.01 | valid ppl  1107.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   200/ 1024 batches | lr 0.01 | ms/batch 38.91 | loss  6.71 | ppl   819.84\n",
      "| epoch   5 |   400/ 1024 batches | lr 0.01 | ms/batch 38.76 | loss  6.70 | ppl   815.27\n",
      "| epoch   5 |   600/ 1024 batches | lr 0.01 | ms/batch 37.53 | loss  6.71 | ppl   824.30\n",
      "| epoch   5 |   800/ 1024 batches | lr 0.01 | ms/batch 38.83 | loss  6.70 | ppl   814.39\n",
      "| epoch   5 |  1000/ 1024 batches | lr 0.01 | ms/batch 38.96 | loss  6.68 | ppl   795.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 40.66s | valid loss  7.04 | valid ppl  1139.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   200/ 1024 batches | lr 0.01 | ms/batch 37.46 | loss  6.71 | ppl   817.24\n",
      "| epoch   6 |   400/ 1024 batches | lr 0.01 | ms/batch 37.39 | loss  6.69 | ppl   801.96\n",
      "| epoch   6 |   600/ 1024 batches | lr 0.01 | ms/batch 39.94 | loss  6.70 | ppl   815.21\n",
      "| epoch   6 |   800/ 1024 batches | lr 0.01 | ms/batch 38.46 | loss  6.69 | ppl   802.07\n",
      "| epoch   6 |  1000/ 1024 batches | lr 0.01 | ms/batch 37.62 | loss  6.67 | ppl   785.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 40.23s | valid loss  7.03 | valid ppl  1128.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   200/ 1024 batches | lr 0.01 | ms/batch 39.81 | loss  6.70 | ppl   809.70\n",
      "| epoch   7 |   400/ 1024 batches | lr 0.01 | ms/batch 39.94 | loss  6.68 | ppl   796.64\n",
      "| epoch   7 |   600/ 1024 batches | lr 0.01 | ms/batch 39.96 | loss  6.70 | ppl   812.66\n",
      "| epoch   7 |   800/ 1024 batches | lr 0.01 | ms/batch 37.13 | loss  6.69 | ppl   800.69\n",
      "| epoch   7 |  1000/ 1024 batches | lr 0.01 | ms/batch 38.64 | loss  6.66 | ppl   781.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 41.29s | valid loss  7.01 | valid ppl  1109.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   200/ 1024 batches | lr 0.01 | ms/batch 39.77 | loss  6.69 | ppl   807.79\n",
      "| epoch   8 |   400/ 1024 batches | lr 0.01 | ms/batch 38.17 | loss  6.67 | ppl   791.43\n",
      "| epoch   8 |   600/ 1024 batches | lr 0.01 | ms/batch 38.37 | loss  6.69 | ppl   807.50\n",
      "| epoch   8 |   800/ 1024 batches | lr 0.01 | ms/batch 39.12 | loss  6.69 | ppl   800.61\n",
      "| epoch   8 |  1000/ 1024 batches | lr 0.01 | ms/batch 38.41 | loss  6.65 | ppl   775.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 40.90s | valid loss  7.00 | valid ppl  1092.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   200/ 1024 batches | lr 0.01 | ms/batch 37.32 | loss  6.69 | ppl   806.93\n",
      "| epoch   9 |   400/ 1024 batches | lr 0.01 | ms/batch 37.57 | loss  6.67 | ppl   789.87\n",
      "| epoch   9 |   600/ 1024 batches | lr 0.01 | ms/batch 39.32 | loss  6.68 | ppl   800.10\n",
      "| epoch   9 |   800/ 1024 batches | lr 0.01 | ms/batch 39.65 | loss  6.68 | ppl   796.27\n",
      "| epoch   9 |  1000/ 1024 batches | lr 0.01 | ms/batch 38.03 | loss  6.65 | ppl   772.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 40.44s | valid loss  7.01 | valid ppl  1108.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   200/ 1024 batches | lr 0.01 | ms/batch 40.10 | loss  6.69 | ppl   803.10\n",
      "| epoch  10 |   400/ 1024 batches | lr 0.01 | ms/batch 39.60 | loss  6.67 | ppl   790.48\n",
      "| epoch  10 |   600/ 1024 batches | lr 0.01 | ms/batch 38.21 | loss  6.68 | ppl   795.94\n",
      "| epoch  10 |   800/ 1024 batches | lr 0.01 | ms/batch 37.97 | loss  6.67 | ppl   789.45\n",
      "| epoch  10 |  1000/ 1024 batches | lr 0.01 | ms/batch 39.63 | loss  6.65 | ppl   771.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 41.21s | valid loss  7.01 | valid ppl  1105.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   200/ 1024 batches | lr 0.01 | ms/batch 38.20 | loss  6.69 | ppl   802.90\n",
      "| epoch  11 |   400/ 1024 batches | lr 0.01 | ms/batch 38.20 | loss  6.67 | ppl   789.32\n",
      "| epoch  11 |   600/ 1024 batches | lr 0.01 | ms/batch 39.35 | loss  6.68 | ppl   796.03\n",
      "| epoch  11 |   800/ 1024 batches | lr 0.01 | ms/batch 39.09 | loss  6.67 | ppl   785.69\n",
      "| epoch  11 |  1000/ 1024 batches | lr 0.01 | ms/batch 37.87 | loss  6.64 | ppl   768.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 40.66s | valid loss  7.03 | valid ppl  1126.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   200/ 1024 batches | lr 0.01 | ms/batch 38.50 | loss  6.69 | ppl   802.32\n",
      "| epoch  12 |   400/ 1024 batches | lr 0.01 | ms/batch 37.71 | loss  6.67 | ppl   790.06\n",
      "| epoch  12 |   600/ 1024 batches | lr 0.01 | ms/batch 38.47 | loss  6.68 | ppl   796.26\n",
      "| epoch  12 |   800/ 1024 batches | lr 0.01 | ms/batch 38.58 | loss  6.67 | ppl   785.09\n",
      "| epoch  12 |  1000/ 1024 batches | lr 0.01 | ms/batch 37.95 | loss  6.65 | ppl   769.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 40.36s | valid loss  7.02 | valid ppl  1124.18\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  13 |   200/ 1024 batches | lr 0.01 | ms/batch 38.20 | loss  6.69 | ppl   803.27\n",
      "| epoch  13 |   400/ 1024 batches | lr 0.01 | ms/batch 38.98 | loss  6.67 | ppl   789.08\n",
      "| epoch  13 |   600/ 1024 batches | lr 0.01 | ms/batch 38.36 | loss  6.68 | ppl   796.20\n",
      "| epoch  13 |   800/ 1024 batches | lr 0.01 | ms/batch 39.28 | loss  6.67 | ppl   784.63\n",
      "| epoch  13 |  1000/ 1024 batches | lr 0.01 | ms/batch 40.92 | loss  6.65 | ppl   770.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 41.22s | valid loss  7.03 | valid ppl  1133.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   200/ 1024 batches | lr 0.01 | ms/batch 37.71 | loss  6.69 | ppl   803.40\n",
      "| epoch  14 |   400/ 1024 batches | lr 0.01 | ms/batch 37.65 | loss  6.67 | ppl   788.28\n",
      "| epoch  14 |   600/ 1024 batches | lr 0.01 | ms/batch 38.73 | loss  6.68 | ppl   796.66\n",
      "| epoch  14 |   800/ 1024 batches | lr 0.01 | ms/batch 38.77 | loss  6.67 | ppl   784.55\n",
      "| epoch  14 |  1000/ 1024 batches | lr 0.01 | ms/batch 38.72 | loss  6.65 | ppl   772.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 40.47s | valid loss  7.04 | valid ppl  1136.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   200/ 1024 batches | lr 0.00 | ms/batch 37.50 | loss  6.69 | ppl   803.06\n",
      "| epoch  15 |   400/ 1024 batches | lr 0.00 | ms/batch 37.98 | loss  6.67 | ppl   788.32\n",
      "| epoch  15 |   600/ 1024 batches | lr 0.00 | ms/batch 37.78 | loss  6.68 | ppl   799.21\n",
      "| epoch  15 |   800/ 1024 batches | lr 0.00 | ms/batch 38.69 | loss  6.66 | ppl   779.60\n",
      "| epoch  15 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.32 | loss  6.64 | ppl   768.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 40.34s | valid loss  7.08 | valid ppl  1187.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   200/ 1024 batches | lr 0.00 | ms/batch 39.20 | loss  6.69 | ppl   803.90\n",
      "| epoch  16 |   400/ 1024 batches | lr 0.00 | ms/batch 39.19 | loss  6.67 | ppl   790.40\n",
      "| epoch  16 |   600/ 1024 batches | lr 0.00 | ms/batch 39.88 | loss  6.69 | ppl   801.56\n",
      "| epoch  16 |   800/ 1024 batches | lr 0.00 | ms/batch 39.41 | loss  6.66 | ppl   781.80\n",
      "| epoch  16 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.19 | loss  6.65 | ppl   775.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 41.67s | valid loss  7.06 | valid ppl  1165.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   200/ 1024 batches | lr 0.00 | ms/batch 37.70 | loss  6.69 | ppl   805.86\n",
      "| epoch  17 |   400/ 1024 batches | lr 0.00 | ms/batch 39.25 | loss  6.67 | ppl   791.60\n",
      "| epoch  17 |   600/ 1024 batches | lr 0.00 | ms/batch 39.35 | loss  6.69 | ppl   803.38\n",
      "| epoch  17 |   800/ 1024 batches | lr 0.00 | ms/batch 38.83 | loss  6.67 | ppl   786.97\n",
      "| epoch  17 |  1000/ 1024 batches | lr 0.00 | ms/batch 36.97 | loss  6.66 | ppl   778.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 40.46s | valid loss  7.04 | valid ppl  1144.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   200/ 1024 batches | lr 0.00 | ms/batch 39.50 | loss  6.69 | ppl   806.92\n",
      "| epoch  18 |   400/ 1024 batches | lr 0.00 | ms/batch 39.30 | loss  6.67 | ppl   792.13\n",
      "| epoch  18 |   600/ 1024 batches | lr 0.00 | ms/batch 39.02 | loss  6.69 | ppl   804.64\n",
      "| epoch  18 |   800/ 1024 batches | lr 0.00 | ms/batch 38.04 | loss  6.67 | ppl   790.33\n",
      "| epoch  18 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.92 | loss  6.66 | ppl   776.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 41.21s | valid loss  7.02 | valid ppl  1121.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   200/ 1024 batches | lr 0.00 | ms/batch 38.72 | loss  6.69 | ppl   805.92\n",
      "| epoch  19 |   400/ 1024 batches | lr 0.00 | ms/batch 37.38 | loss  6.68 | ppl   792.61\n",
      "| epoch  19 |   600/ 1024 batches | lr 0.00 | ms/batch 37.88 | loss  6.69 | ppl   804.94\n",
      "| epoch  19 |   800/ 1024 batches | lr 0.00 | ms/batch 38.79 | loss  6.68 | ppl   792.35\n",
      "| epoch  19 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.77 | loss  6.66 | ppl   778.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 40.64s | valid loss  7.03 | valid ppl  1129.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   200/ 1024 batches | lr 0.00 | ms/batch 39.43 | loss  6.69 | ppl   807.79\n",
      "| epoch  20 |   400/ 1024 batches | lr 0.00 | ms/batch 37.79 | loss  6.68 | ppl   793.46\n",
      "| epoch  20 |   600/ 1024 batches | lr 0.00 | ms/batch 39.56 | loss  6.69 | ppl   805.50\n",
      "| epoch  20 |   800/ 1024 batches | lr 0.00 | ms/batch 38.56 | loss  6.68 | ppl   792.86\n",
      "| epoch  20 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.09 | loss  6.66 | ppl   778.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 40.80s | valid loss  7.04 | valid ppl  1140.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   200/ 1024 batches | lr 0.00 | ms/batch 39.28 | loss  6.70 | ppl   809.31\n",
      "| epoch  21 |   400/ 1024 batches | lr 0.00 | ms/batch 39.37 | loss  6.68 | ppl   795.19\n",
      "| epoch  21 |   600/ 1024 batches | lr 0.00 | ms/batch 36.98 | loss  6.69 | ppl   804.83\n",
      "| epoch  21 |   800/ 1024 batches | lr 0.00 | ms/batch 37.02 | loss  6.68 | ppl   793.88\n",
      "| epoch  21 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.49 | loss  6.66 | ppl   779.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 40.41s | valid loss  7.05 | valid ppl  1151.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   200/ 1024 batches | lr 0.00 | ms/batch 37.83 | loss  6.70 | ppl   809.13\n",
      "| epoch  22 |   400/ 1024 batches | lr 0.00 | ms/batch 37.04 | loss  6.68 | ppl   797.33\n",
      "| epoch  22 |   600/ 1024 batches | lr 0.00 | ms/batch 37.03 | loss  6.69 | ppl   806.51\n",
      "| epoch  22 |   800/ 1024 batches | lr 0.00 | ms/batch 37.80 | loss  6.68 | ppl   794.45\n",
      "| epoch  22 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.50 | loss  6.66 | ppl   780.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 39.98s | valid loss  7.03 | valid ppl  1132.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |   200/ 1024 batches | lr 0.00 | ms/batch 38.52 | loss  6.70 | ppl   810.49\n",
      "| epoch  23 |   400/ 1024 batches | lr 0.00 | ms/batch 37.78 | loss  6.68 | ppl   798.85\n",
      "| epoch  23 |   600/ 1024 batches | lr 0.00 | ms/batch 39.61 | loss  6.70 | ppl   808.95\n",
      "| epoch  23 |   800/ 1024 batches | lr 0.00 | ms/batch 39.29 | loss  6.68 | ppl   795.74\n",
      "| epoch  23 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.25 | loss  6.66 | ppl   782.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 40.92s | valid loss  7.00 | valid ppl  1102.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   200/ 1024 batches | lr 0.00 | ms/batch 38.82 | loss  6.70 | ppl   812.27\n",
      "| epoch  24 |   400/ 1024 batches | lr 0.00 | ms/batch 37.72 | loss  6.68 | ppl   799.42\n",
      "| epoch  24 |   600/ 1024 batches | lr 0.00 | ms/batch 39.75 | loss  6.70 | ppl   810.57\n",
      "| epoch  24 |   800/ 1024 batches | lr 0.00 | ms/batch 39.27 | loss  6.68 | ppl   797.14\n",
      "| epoch  24 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.98 | loss  6.66 | ppl   783.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 41.06s | valid loss  6.99 | valid ppl  1086.36\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  25 |   200/ 1024 batches | lr 0.00 | ms/batch 37.01 | loss  6.70 | ppl   814.02\n",
      "| epoch  25 |   400/ 1024 batches | lr 0.00 | ms/batch 39.81 | loss  6.68 | ppl   799.99\n",
      "| epoch  25 |   600/ 1024 batches | lr 0.00 | ms/batch 39.00 | loss  6.70 | ppl   811.56\n",
      "| epoch  25 |   800/ 1024 batches | lr 0.00 | ms/batch 39.41 | loss  6.68 | ppl   799.59\n",
      "| epoch  25 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.80 | loss  6.67 | ppl   784.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 40.71s | valid loss  6.99 | valid ppl  1090.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   200/ 1024 batches | lr 0.00 | ms/batch 37.67 | loss  6.70 | ppl   815.77\n",
      "| epoch  26 |   400/ 1024 batches | lr 0.00 | ms/batch 39.04 | loss  6.69 | ppl   800.44\n",
      "| epoch  26 |   600/ 1024 batches | lr 0.00 | ms/batch 37.45 | loss  6.70 | ppl   812.97\n",
      "| epoch  26 |   800/ 1024 batches | lr 0.00 | ms/batch 37.66 | loss  6.69 | ppl   801.64\n",
      "| epoch  26 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.42 | loss  6.67 | ppl   786.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 40.13s | valid loss  7.00 | valid ppl  1091.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   200/ 1024 batches | lr 0.00 | ms/batch 38.23 | loss  6.71 | ppl   817.19\n",
      "| epoch  27 |   400/ 1024 batches | lr 0.00 | ms/batch 36.99 | loss  6.69 | ppl   800.94\n",
      "| epoch  27 |   600/ 1024 batches | lr 0.00 | ms/batch 37.70 | loss  6.70 | ppl   815.16\n",
      "| epoch  27 |   800/ 1024 batches | lr 0.00 | ms/batch 38.71 | loss  6.69 | ppl   803.06\n",
      "| epoch  27 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.83 | loss  6.67 | ppl   788.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 40.15s | valid loss  6.98 | valid ppl  1080.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   200/ 1024 batches | lr 0.00 | ms/batch 37.18 | loss  6.71 | ppl   818.03\n",
      "| epoch  28 |   400/ 1024 batches | lr 0.00 | ms/batch 37.77 | loss  6.69 | ppl   801.99\n",
      "| epoch  28 |   600/ 1024 batches | lr 0.00 | ms/batch 39.43 | loss  6.71 | ppl   816.79\n",
      "| epoch  28 |   800/ 1024 batches | lr 0.00 | ms/batch 36.83 | loss  6.69 | ppl   805.01\n",
      "| epoch  28 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.93 | loss  6.67 | ppl   790.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 39.91s | valid loss  6.97 | valid ppl  1068.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   200/ 1024 batches | lr 0.00 | ms/batch 38.01 | loss  6.71 | ppl   818.70\n",
      "| epoch  29 |   400/ 1024 batches | lr 0.00 | ms/batch 39.02 | loss  6.69 | ppl   803.58\n",
      "| epoch  29 |   600/ 1024 batches | lr 0.00 | ms/batch 38.01 | loss  6.71 | ppl   818.19\n",
      "| epoch  29 |   800/ 1024 batches | lr 0.00 | ms/batch 37.63 | loss  6.69 | ppl   807.30\n",
      "| epoch  29 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.13 | loss  6.68 | ppl   792.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 40.46s | valid loss  6.97 | valid ppl  1065.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   200/ 1024 batches | lr 0.00 | ms/batch 37.80 | loss  6.71 | ppl   820.40\n",
      "| epoch  30 |   400/ 1024 batches | lr 0.00 | ms/batch 37.55 | loss  6.69 | ppl   805.71\n",
      "| epoch  30 |   600/ 1024 batches | lr 0.00 | ms/batch 39.44 | loss  6.71 | ppl   819.41\n",
      "| epoch  30 |   800/ 1024 batches | lr 0.00 | ms/batch 38.34 | loss  6.70 | ppl   809.65\n",
      "| epoch  30 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.57 | loss  6.68 | ppl   795.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 40.20s | valid loss  6.97 | valid ppl  1067.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |   200/ 1024 batches | lr 0.00 | ms/batch 37.12 | loss  6.71 | ppl   822.97\n",
      "| epoch  31 |   400/ 1024 batches | lr 0.00 | ms/batch 36.91 | loss  6.69 | ppl   808.16\n",
      "| epoch  31 |   600/ 1024 batches | lr 0.00 | ms/batch 38.38 | loss  6.71 | ppl   820.92\n",
      "| epoch  31 |   800/ 1024 batches | lr 0.00 | ms/batch 38.09 | loss  6.70 | ppl   811.59\n",
      "| epoch  31 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.39 | loss  6.68 | ppl   797.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 39.73s | valid loss  6.97 | valid ppl  1061.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   200/ 1024 batches | lr 0.00 | ms/batch 38.06 | loss  6.72 | ppl   825.57\n",
      "| epoch  32 |   400/ 1024 batches | lr 0.00 | ms/batch 39.80 | loss  6.70 | ppl   810.34\n",
      "| epoch  32 |   600/ 1024 batches | lr 0.00 | ms/batch 38.11 | loss  6.71 | ppl   823.48\n",
      "| epoch  32 |   800/ 1024 batches | lr 0.00 | ms/batch 38.67 | loss  6.70 | ppl   813.03\n",
      "| epoch  32 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.56 | loss  6.68 | ppl   799.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 40.71s | valid loss  6.96 | valid ppl  1053.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   200/ 1024 batches | lr 0.00 | ms/batch 37.14 | loss  6.72 | ppl   828.22\n",
      "| epoch  33 |   400/ 1024 batches | lr 0.00 | ms/batch 37.96 | loss  6.70 | ppl   812.43\n",
      "| epoch  33 |   600/ 1024 batches | lr 0.00 | ms/batch 40.21 | loss  6.72 | ppl   825.77\n",
      "| epoch  33 |   800/ 1024 batches | lr 0.00 | ms/batch 38.04 | loss  6.70 | ppl   814.27\n",
      "| epoch  33 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.05 | loss  6.68 | ppl   800.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 40.13s | valid loss  6.95 | valid ppl  1047.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |   200/ 1024 batches | lr 0.00 | ms/batch 37.82 | loss  6.72 | ppl   831.22\n",
      "| epoch  34 |   400/ 1024 batches | lr 0.00 | ms/batch 37.58 | loss  6.70 | ppl   814.88\n",
      "| epoch  34 |   600/ 1024 batches | lr 0.00 | ms/batch 37.99 | loss  6.72 | ppl   827.99\n",
      "| epoch  34 |   800/ 1024 batches | lr 0.00 | ms/batch 36.89 | loss  6.70 | ppl   815.84\n",
      "| epoch  34 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.11 | loss  6.69 | ppl   801.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 40.18s | valid loss  6.95 | valid ppl  1043.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   200/ 1024 batches | lr 0.00 | ms/batch 38.26 | loss  6.73 | ppl   833.94\n",
      "| epoch  35 |   400/ 1024 batches | lr 0.00 | ms/batch 38.10 | loss  6.71 | ppl   817.47\n",
      "| epoch  35 |   600/ 1024 batches | lr 0.00 | ms/batch 38.02 | loss  6.72 | ppl   829.95\n",
      "| epoch  35 |   800/ 1024 batches | lr 0.00 | ms/batch 39.25 | loss  6.71 | ppl   817.51\n",
      "| epoch  35 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.11 | loss  6.69 | ppl   803.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 41.17s | valid loss  6.95 | valid ppl  1041.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   200/ 1024 batches | lr 0.00 | ms/batch 39.59 | loss  6.73 | ppl   835.95\n",
      "| epoch  36 |   400/ 1024 batches | lr 0.00 | ms/batch 38.19 | loss  6.71 | ppl   819.99\n",
      "| epoch  36 |   600/ 1024 batches | lr 0.00 | ms/batch 39.71 | loss  6.72 | ppl   832.02\n",
      "| epoch  36 |   800/ 1024 batches | lr 0.00 | ms/batch 39.48 | loss  6.71 | ppl   819.45\n",
      "| epoch  36 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.94 | loss  6.69 | ppl   806.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 41.12s | valid loss  6.95 | valid ppl  1042.04\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  37 |   200/ 1024 batches | lr 0.00 | ms/batch 38.61 | loss  6.73 | ppl   838.19\n",
      "| epoch  37 |   400/ 1024 batches | lr 0.00 | ms/batch 39.18 | loss  6.71 | ppl   823.19\n",
      "| epoch  37 |   600/ 1024 batches | lr 0.00 | ms/batch 39.27 | loss  6.73 | ppl   834.63\n",
      "| epoch  37 |   800/ 1024 batches | lr 0.00 | ms/batch 39.44 | loss  6.71 | ppl   822.08\n",
      "| epoch  37 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.61 | loss  6.70 | ppl   809.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 41.64s | valid loss  6.95 | valid ppl  1038.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   200/ 1024 batches | lr 0.00 | ms/batch 38.27 | loss  6.73 | ppl   840.29\n",
      "| epoch  38 |   400/ 1024 batches | lr 0.00 | ms/batch 38.30 | loss  6.72 | ppl   825.74\n",
      "| epoch  38 |   600/ 1024 batches | lr 0.00 | ms/batch 39.83 | loss  6.73 | ppl   836.86\n",
      "| epoch  38 |   800/ 1024 batches | lr 0.00 | ms/batch 40.35 | loss  6.72 | ppl   825.25\n",
      "| epoch  38 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.17 | loss  6.70 | ppl   811.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 41.33s | valid loss  6.94 | valid ppl  1034.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   200/ 1024 batches | lr 0.00 | ms/batch 39.27 | loss  6.74 | ppl   843.02\n",
      "| epoch  39 |   400/ 1024 batches | lr 0.00 | ms/batch 38.88 | loss  6.72 | ppl   828.39\n",
      "| epoch  39 |   600/ 1024 batches | lr 0.00 | ms/batch 37.02 | loss  6.73 | ppl   839.43\n",
      "| epoch  39 |   800/ 1024 batches | lr 0.00 | ms/batch 37.86 | loss  6.72 | ppl   828.59\n",
      "| epoch  39 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.04 | loss  6.70 | ppl   813.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 40.14s | valid loss  6.94 | valid ppl  1032.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   200/ 1024 batches | lr 0.00 | ms/batch 39.46 | loss  6.74 | ppl   846.54\n",
      "| epoch  40 |   400/ 1024 batches | lr 0.00 | ms/batch 39.01 | loss  6.72 | ppl   831.51\n",
      "| epoch  40 |   600/ 1024 batches | lr 0.00 | ms/batch 37.35 | loss  6.74 | ppl   841.96\n",
      "| epoch  40 |   800/ 1024 batches | lr 0.00 | ms/batch 37.07 | loss  6.72 | ppl   831.85\n",
      "| epoch  40 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.74 | loss  6.70 | ppl   816.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 40.44s | valid loss  6.94 | valid ppl  1033.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |   200/ 1024 batches | lr 0.00 | ms/batch 39.43 | loss  6.75 | ppl   850.36\n",
      "| epoch  41 |   400/ 1024 batches | lr 0.00 | ms/batch 38.57 | loss  6.73 | ppl   834.60\n",
      "| epoch  41 |   600/ 1024 batches | lr 0.00 | ms/batch 37.25 | loss  6.74 | ppl   844.40\n",
      "| epoch  41 |   800/ 1024 batches | lr 0.00 | ms/batch 38.37 | loss  6.73 | ppl   834.89\n",
      "| epoch  41 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.13 | loss  6.71 | ppl   819.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 40.69s | valid loss  6.94 | valid ppl  1029.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   200/ 1024 batches | lr 0.00 | ms/batch 37.77 | loss  6.75 | ppl   854.12\n",
      "| epoch  42 |   400/ 1024 batches | lr 0.00 | ms/batch 37.96 | loss  6.73 | ppl   837.83\n",
      "| epoch  42 |   600/ 1024 batches | lr 0.00 | ms/batch 38.29 | loss  6.74 | ppl   846.80\n",
      "| epoch  42 |   800/ 1024 batches | lr 0.00 | ms/batch 37.97 | loss  6.73 | ppl   837.66\n",
      "| epoch  42 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.64 | loss  6.71 | ppl   822.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 39.98s | valid loss  6.93 | valid ppl  1022.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   200/ 1024 batches | lr 0.00 | ms/batch 38.82 | loss  6.75 | ppl   857.44\n",
      "| epoch  43 |   400/ 1024 batches | lr 0.00 | ms/batch 40.22 | loss  6.73 | ppl   840.93\n",
      "| epoch  43 |   600/ 1024 batches | lr 0.00 | ms/batch 38.39 | loss  6.74 | ppl   849.36\n",
      "| epoch  43 |   800/ 1024 batches | lr 0.00 | ms/batch 38.13 | loss  6.73 | ppl   840.43\n",
      "| epoch  43 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.97 | loss  6.72 | ppl   825.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 41.05s | valid loss  6.93 | valid ppl  1017.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   200/ 1024 batches | lr 0.00 | ms/batch 37.48 | loss  6.76 | ppl   860.48\n",
      "| epoch  44 |   400/ 1024 batches | lr 0.00 | ms/batch 38.61 | loss  6.74 | ppl   844.05\n",
      "| epoch  44 |   600/ 1024 batches | lr 0.00 | ms/batch 37.00 | loss  6.75 | ppl   852.19\n",
      "| epoch  44 |   800/ 1024 batches | lr 0.00 | ms/batch 38.12 | loss  6.74 | ppl   843.46\n",
      "| epoch  44 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.21 | loss  6.72 | ppl   828.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 40.41s | valid loss  6.92 | valid ppl  1014.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |   200/ 1024 batches | lr 0.00 | ms/batch 37.65 | loss  6.76 | ppl   863.66\n",
      "| epoch  45 |   400/ 1024 batches | lr 0.00 | ms/batch 36.87 | loss  6.74 | ppl   847.30\n",
      "| epoch  45 |   600/ 1024 batches | lr 0.00 | ms/batch 38.13 | loss  6.75 | ppl   855.06\n",
      "| epoch  45 |   800/ 1024 batches | lr 0.00 | ms/batch 38.08 | loss  6.74 | ppl   846.83\n",
      "| epoch  45 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.84 | loss  6.72 | ppl   831.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 39.84s | valid loss  6.92 | valid ppl  1011.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   200/ 1024 batches | lr 0.00 | ms/batch 38.36 | loss  6.77 | ppl   867.27\n",
      "| epoch  46 |   400/ 1024 batches | lr 0.00 | ms/batch 39.09 | loss  6.75 | ppl   850.12\n",
      "| epoch  46 |   600/ 1024 batches | lr 0.00 | ms/batch 38.00 | loss  6.75 | ppl   858.13\n",
      "| epoch  46 |   800/ 1024 batches | lr 0.00 | ms/batch 38.36 | loss  6.75 | ppl   850.22\n",
      "| epoch  46 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.40 | loss  6.73 | ppl   834.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 40.35s | valid loss  6.91 | valid ppl  1005.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   200/ 1024 batches | lr 0.00 | ms/batch 38.24 | loss  6.77 | ppl   871.07\n",
      "| epoch  47 |   400/ 1024 batches | lr 0.00 | ms/batch 38.84 | loss  6.75 | ppl   853.27\n",
      "| epoch  47 |   600/ 1024 batches | lr 0.00 | ms/batch 38.88 | loss  6.76 | ppl   861.38\n",
      "| epoch  47 |   800/ 1024 batches | lr 0.00 | ms/batch 38.78 | loss  6.75 | ppl   853.48\n",
      "| epoch  47 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.90 | loss  6.73 | ppl   837.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 40.88s | valid loss  6.91 | valid ppl   999.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   200/ 1024 batches | lr 0.00 | ms/batch 37.54 | loss  6.77 | ppl   874.89\n",
      "| epoch  48 |   400/ 1024 batches | lr 0.00 | ms/batch 38.97 | loss  6.75 | ppl   856.32\n",
      "| epoch  48 |   600/ 1024 batches | lr 0.00 | ms/batch 40.34 | loss  6.76 | ppl   864.63\n",
      "| epoch  48 |   800/ 1024 batches | lr 0.00 | ms/batch 38.86 | loss  6.75 | ppl   856.76\n",
      "| epoch  48 |  1000/ 1024 batches | lr 0.00 | ms/batch 36.90 | loss  6.74 | ppl   841.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 40.70s | valid loss  6.90 | valid ppl   994.78\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  49 |   200/ 1024 batches | lr 0.00 | ms/batch 38.20 | loss  6.78 | ppl   878.66\n",
      "| epoch  49 |   400/ 1024 batches | lr 0.00 | ms/batch 38.72 | loss  6.76 | ppl   859.76\n",
      "| epoch  49 |   600/ 1024 batches | lr 0.00 | ms/batch 39.18 | loss  6.77 | ppl   867.62\n",
      "| epoch  49 |   800/ 1024 batches | lr 0.00 | ms/batch 38.37 | loss  6.76 | ppl   860.28\n",
      "| epoch  49 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.70 | loss  6.74 | ppl   845.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 40.76s | valid loss  6.90 | valid ppl   989.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   200/ 1024 batches | lr 0.00 | ms/batch 38.26 | loss  6.78 | ppl   882.59\n",
      "| epoch  50 |   400/ 1024 batches | lr 0.00 | ms/batch 38.37 | loss  6.76 | ppl   862.94\n",
      "| epoch  50 |   600/ 1024 batches | lr 0.00 | ms/batch 38.46 | loss  6.77 | ppl   871.03\n",
      "| epoch  50 |   800/ 1024 batches | lr 0.00 | ms/batch 38.99 | loss  6.76 | ppl   863.82\n",
      "| epoch  50 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.37 | loss  6.74 | ppl   849.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 40.36s | valid loss  6.89 | valid ppl   983.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |   200/ 1024 batches | lr 0.00 | ms/batch 37.64 | loss  6.79 | ppl   886.56\n",
      "| epoch  51 |   400/ 1024 batches | lr 0.00 | ms/batch 37.91 | loss  6.76 | ppl   866.19\n",
      "| epoch  51 |   600/ 1024 batches | lr 0.00 | ms/batch 39.86 | loss  6.77 | ppl   874.56\n",
      "| epoch  51 |   800/ 1024 batches | lr 0.00 | ms/batch 38.06 | loss  6.77 | ppl   867.10\n",
      "| epoch  51 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.69 | loss  6.75 | ppl   853.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 40.35s | valid loss  6.88 | valid ppl   975.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |   200/ 1024 batches | lr 0.00 | ms/batch 38.97 | loss  6.79 | ppl   890.68\n",
      "| epoch  52 |   400/ 1024 batches | lr 0.00 | ms/batch 38.27 | loss  6.77 | ppl   869.25\n",
      "| epoch  52 |   600/ 1024 batches | lr 0.00 | ms/batch 37.36 | loss  6.78 | ppl   878.15\n",
      "| epoch  52 |   800/ 1024 batches | lr 0.00 | ms/batch 38.54 | loss  6.77 | ppl   870.52\n",
      "| epoch  52 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.52 | loss  6.75 | ppl   856.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 40.63s | valid loss  6.87 | valid ppl   967.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |   200/ 1024 batches | lr 0.00 | ms/batch 37.57 | loss  6.80 | ppl   894.58\n",
      "| epoch  53 |   400/ 1024 batches | lr 0.00 | ms/batch 38.42 | loss  6.77 | ppl   872.15\n",
      "| epoch  53 |   600/ 1024 batches | lr 0.00 | ms/batch 38.28 | loss  6.78 | ppl   882.03\n",
      "| epoch  53 |   800/ 1024 batches | lr 0.00 | ms/batch 37.95 | loss  6.77 | ppl   873.92\n",
      "| epoch  53 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.81 | loss  6.76 | ppl   860.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 40.32s | valid loss  6.87 | valid ppl   958.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |   200/ 1024 batches | lr 0.00 | ms/batch 38.62 | loss  6.80 | ppl   898.54\n",
      "| epoch  54 |   400/ 1024 batches | lr 0.00 | ms/batch 38.35 | loss  6.77 | ppl   875.14\n",
      "| epoch  54 |   600/ 1024 batches | lr 0.00 | ms/batch 38.68 | loss  6.79 | ppl   886.01\n",
      "| epoch  54 |   800/ 1024 batches | lr 0.00 | ms/batch 37.97 | loss  6.78 | ppl   877.33\n",
      "| epoch  54 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.88 | loss  6.76 | ppl   864.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 40.42s | valid loss  6.86 | valid ppl   951.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |   200/ 1024 batches | lr 0.00 | ms/batch 37.44 | loss  6.81 | ppl   902.35\n",
      "| epoch  55 |   400/ 1024 batches | lr 0.00 | ms/batch 37.20 | loss  6.78 | ppl   878.09\n",
      "| epoch  55 |   600/ 1024 batches | lr 0.00 | ms/batch 37.96 | loss  6.79 | ppl   889.87\n",
      "| epoch  55 |   800/ 1024 batches | lr 0.00 | ms/batch 38.95 | loss  6.78 | ppl   880.86\n",
      "| epoch  55 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.60 | loss  6.77 | ppl   867.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 39.99s | valid loss  6.85 | valid ppl   946.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |   200/ 1024 batches | lr 0.00 | ms/batch 37.18 | loss  6.81 | ppl   906.26\n",
      "| epoch  56 |   400/ 1024 batches | lr 0.00 | ms/batch 38.41 | loss  6.78 | ppl   881.55\n",
      "| epoch  56 |   600/ 1024 batches | lr 0.00 | ms/batch 41.39 | loss  6.80 | ppl   893.79\n",
      "| epoch  56 |   800/ 1024 batches | lr 0.00 | ms/batch 36.98 | loss  6.79 | ppl   884.50\n",
      "| epoch  56 |  1000/ 1024 batches | lr 0.00 | ms/batch 36.87 | loss  6.77 | ppl   871.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 40.30s | valid loss  6.85 | valid ppl   942.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |   200/ 1024 batches | lr 0.00 | ms/batch 38.59 | loss  6.81 | ppl   910.37\n",
      "| epoch  57 |   400/ 1024 batches | lr 0.00 | ms/batch 38.68 | loss  6.79 | ppl   885.39\n",
      "| epoch  57 |   600/ 1024 batches | lr 0.00 | ms/batch 37.77 | loss  6.80 | ppl   897.72\n",
      "| epoch  57 |   800/ 1024 batches | lr 0.00 | ms/batch 38.15 | loss  6.79 | ppl   887.72\n",
      "| epoch  57 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.53 | loss  6.77 | ppl   874.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 40.63s | valid loss  6.85 | valid ppl   939.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |   200/ 1024 batches | lr 0.00 | ms/batch 38.89 | loss  6.82 | ppl   914.32\n",
      "| epoch  58 |   400/ 1024 batches | lr 0.00 | ms/batch 39.53 | loss  6.79 | ppl   889.33\n",
      "| epoch  58 |   600/ 1024 batches | lr 0.00 | ms/batch 38.10 | loss  6.80 | ppl   901.51\n",
      "| epoch  58 |   800/ 1024 batches | lr 0.00 | ms/batch 40.19 | loss  6.79 | ppl   891.32\n",
      "| epoch  58 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.11 | loss  6.78 | ppl   877.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 40.86s | valid loss  6.84 | valid ppl   936.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |   200/ 1024 batches | lr 0.00 | ms/batch 38.25 | loss  6.82 | ppl   918.40\n",
      "| epoch  59 |   400/ 1024 batches | lr 0.00 | ms/batch 40.34 | loss  6.80 | ppl   893.59\n",
      "| epoch  59 |   600/ 1024 batches | lr 0.00 | ms/batch 38.84 | loss  6.81 | ppl   905.54\n",
      "| epoch  59 |   800/ 1024 batches | lr 0.00 | ms/batch 36.88 | loss  6.80 | ppl   895.32\n",
      "| epoch  59 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.96 | loss  6.78 | ppl   881.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 40.62s | valid loss  6.84 | valid ppl   934.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |   200/ 1024 batches | lr 0.00 | ms/batch 38.01 | loss  6.83 | ppl   922.84\n",
      "| epoch  60 |   400/ 1024 batches | lr 0.00 | ms/batch 38.52 | loss  6.80 | ppl   898.02\n",
      "| epoch  60 |   600/ 1024 batches | lr 0.00 | ms/batch 37.64 | loss  6.81 | ppl   909.38\n",
      "| epoch  60 |   800/ 1024 batches | lr 0.00 | ms/batch 39.77 | loss  6.80 | ppl   899.23\n",
      "| epoch  60 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.07 | loss  6.79 | ppl   884.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 40.47s | valid loss  6.84 | valid ppl   932.36\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  61 |   200/ 1024 batches | lr 0.00 | ms/batch 37.99 | loss  6.83 | ppl   927.20\n",
      "| epoch  61 |   400/ 1024 batches | lr 0.00 | ms/batch 37.40 | loss  6.81 | ppl   902.59\n",
      "| epoch  61 |   600/ 1024 batches | lr 0.00 | ms/batch 38.36 | loss  6.82 | ppl   913.47\n",
      "| epoch  61 |   800/ 1024 batches | lr 0.00 | ms/batch 38.27 | loss  6.81 | ppl   902.97\n",
      "| epoch  61 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.30 | loss  6.79 | ppl   888.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 40.01s | valid loss  6.84 | valid ppl   930.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |   200/ 1024 batches | lr 0.00 | ms/batch 39.39 | loss  6.84 | ppl   931.29\n",
      "| epoch  62 |   400/ 1024 batches | lr 0.00 | ms/batch 40.05 | loss  6.81 | ppl   907.23\n",
      "| epoch  62 |   600/ 1024 batches | lr 0.00 | ms/batch 37.67 | loss  6.82 | ppl   917.18\n",
      "| epoch  62 |   800/ 1024 batches | lr 0.00 | ms/batch 38.28 | loss  6.81 | ppl   906.60\n",
      "| epoch  62 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.23 | loss  6.79 | ppl   891.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 40.83s | valid loss  6.83 | valid ppl   926.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |   200/ 1024 batches | lr 0.00 | ms/batch 37.58 | loss  6.84 | ppl   935.34\n",
      "| epoch  63 |   400/ 1024 batches | lr 0.00 | ms/batch 38.49 | loss  6.82 | ppl   912.11\n",
      "| epoch  63 |   600/ 1024 batches | lr 0.00 | ms/batch 38.54 | loss  6.83 | ppl   921.00\n",
      "| epoch  63 |   800/ 1024 batches | lr 0.00 | ms/batch 39.47 | loss  6.81 | ppl   910.11\n",
      "| epoch  63 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.02 | loss  6.80 | ppl   895.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 40.75s | valid loss  6.83 | valid ppl   921.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |   200/ 1024 batches | lr 0.00 | ms/batch 37.77 | loss  6.85 | ppl   939.53\n",
      "| epoch  64 |   400/ 1024 batches | lr 0.00 | ms/batch 38.43 | loss  6.82 | ppl   917.28\n",
      "| epoch  64 |   600/ 1024 batches | lr 0.00 | ms/batch 38.12 | loss  6.83 | ppl   924.79\n",
      "| epoch  64 |   800/ 1024 batches | lr 0.00 | ms/batch 37.35 | loss  6.82 | ppl   913.48\n",
      "| epoch  64 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.58 | loss  6.80 | ppl   899.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 40.32s | valid loss  6.82 | valid ppl   916.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |   200/ 1024 batches | lr 0.00 | ms/batch 39.17 | loss  6.85 | ppl   943.20\n",
      "| epoch  65 |   400/ 1024 batches | lr 0.00 | ms/batch 37.73 | loss  6.83 | ppl   922.78\n",
      "| epoch  65 |   600/ 1024 batches | lr 0.00 | ms/batch 37.00 | loss  6.83 | ppl   928.17\n",
      "| epoch  65 |   800/ 1024 batches | lr 0.00 | ms/batch 38.00 | loss  6.82 | ppl   916.59\n",
      "| epoch  65 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.41 | loss  6.81 | ppl   903.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 40.14s | valid loss  6.81 | valid ppl   908.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |   200/ 1024 batches | lr 0.00 | ms/batch 37.29 | loss  6.85 | ppl   946.74\n",
      "| epoch  66 |   400/ 1024 batches | lr 0.00 | ms/batch 37.87 | loss  6.83 | ppl   927.56\n",
      "| epoch  66 |   600/ 1024 batches | lr 0.00 | ms/batch 38.23 | loss  6.84 | ppl   931.30\n",
      "| epoch  66 |   800/ 1024 batches | lr 0.00 | ms/batch 37.40 | loss  6.82 | ppl   919.95\n",
      "| epoch  66 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.24 | loss  6.81 | ppl   908.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 39.68s | valid loss  6.80 | valid ppl   901.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |   200/ 1024 batches | lr 0.00 | ms/batch 38.73 | loss  6.86 | ppl   950.33\n",
      "| epoch  67 |   400/ 1024 batches | lr 0.00 | ms/batch 38.31 | loss  6.84 | ppl   932.66\n",
      "| epoch  67 |   600/ 1024 batches | lr 0.00 | ms/batch 38.10 | loss  6.84 | ppl   934.10\n",
      "| epoch  67 |   800/ 1024 batches | lr 0.00 | ms/batch 38.10 | loss  6.83 | ppl   923.17\n",
      "| epoch  67 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.70 | loss  6.82 | ppl   912.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 40.51s | valid loss  6.80 | valid ppl   894.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |   200/ 1024 batches | lr 0.00 | ms/batch 38.50 | loss  6.86 | ppl   953.96\n",
      "| epoch  68 |   400/ 1024 batches | lr 0.00 | ms/batch 37.40 | loss  6.84 | ppl   937.28\n",
      "| epoch  68 |   600/ 1024 batches | lr 0.00 | ms/batch 36.93 | loss  6.84 | ppl   936.65\n",
      "| epoch  68 |   800/ 1024 batches | lr 0.00 | ms/batch 39.16 | loss  6.83 | ppl   926.59\n",
      "| epoch  68 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.89 | loss  6.82 | ppl   916.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 40.27s | valid loss  6.79 | valid ppl   887.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |   200/ 1024 batches | lr 0.00 | ms/batch 38.99 | loss  6.86 | ppl   957.47\n",
      "| epoch  69 |   400/ 1024 batches | lr 0.00 | ms/batch 39.44 | loss  6.85 | ppl   941.35\n",
      "| epoch  69 |   600/ 1024 batches | lr 0.00 | ms/batch 38.94 | loss  6.84 | ppl   939.16\n",
      "| epoch  69 |   800/ 1024 batches | lr 0.00 | ms/batch 38.12 | loss  6.84 | ppl   929.96\n",
      "| epoch  69 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.65 | loss  6.82 | ppl   920.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 40.86s | valid loss  6.78 | valid ppl   882.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |   200/ 1024 batches | lr 0.00 | ms/batch 39.38 | loss  6.87 | ppl   960.84\n",
      "| epoch  70 |   400/ 1024 batches | lr 0.00 | ms/batch 38.55 | loss  6.85 | ppl   945.14\n",
      "| epoch  70 |   600/ 1024 batches | lr 0.00 | ms/batch 37.19 | loss  6.85 | ppl   941.70\n",
      "| epoch  70 |   800/ 1024 batches | lr 0.00 | ms/batch 37.23 | loss  6.84 | ppl   933.31\n",
      "| epoch  70 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.81 | loss  6.83 | ppl   923.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 40.57s | valid loss  6.78 | valid ppl   876.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 |   200/ 1024 batches | lr 0.00 | ms/batch 38.12 | loss  6.87 | ppl   964.23\n",
      "| epoch  71 |   400/ 1024 batches | lr 0.00 | ms/batch 38.87 | loss  6.86 | ppl   948.76\n",
      "| epoch  71 |   600/ 1024 batches | lr 0.00 | ms/batch 37.95 | loss  6.85 | ppl   944.31\n",
      "| epoch  71 |   800/ 1024 batches | lr 0.00 | ms/batch 39.97 | loss  6.84 | ppl   936.68\n",
      "| epoch  71 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.69 | loss  6.83 | ppl   927.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 40.70s | valid loss  6.77 | valid ppl   871.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |   200/ 1024 batches | lr 0.00 | ms/batch 38.15 | loss  6.87 | ppl   967.61\n",
      "| epoch  72 |   400/ 1024 batches | lr 0.00 | ms/batch 38.48 | loss  6.86 | ppl   952.16\n",
      "| epoch  72 |   600/ 1024 batches | lr 0.00 | ms/batch 37.38 | loss  6.85 | ppl   947.11\n",
      "| epoch  72 |   800/ 1024 batches | lr 0.00 | ms/batch 37.63 | loss  6.85 | ppl   939.90\n",
      "| epoch  72 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.78 | loss  6.84 | ppl   931.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 39.97s | valid loss  6.76 | valid ppl   866.35\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  73 |   200/ 1024 batches | lr 0.00 | ms/batch 40.15 | loss  6.88 | ppl   971.00\n",
      "| epoch  73 |   400/ 1024 batches | lr 0.00 | ms/batch 38.06 | loss  6.86 | ppl   955.48\n",
      "| epoch  73 |   600/ 1024 batches | lr 0.00 | ms/batch 38.36 | loss  6.86 | ppl   950.03\n",
      "| epoch  73 |   800/ 1024 batches | lr 0.00 | ms/batch 38.79 | loss  6.85 | ppl   943.15\n",
      "| epoch  73 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.07 | loss  6.84 | ppl   934.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 40.96s | valid loss  6.76 | valid ppl   861.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |   200/ 1024 batches | lr 0.00 | ms/batch 37.94 | loss  6.88 | ppl   974.61\n",
      "| epoch  74 |   400/ 1024 batches | lr 0.00 | ms/batch 37.31 | loss  6.87 | ppl   958.72\n",
      "| epoch  74 |   600/ 1024 batches | lr 0.00 | ms/batch 39.09 | loss  6.86 | ppl   952.91\n",
      "| epoch  74 |   800/ 1024 batches | lr 0.00 | ms/batch 37.68 | loss  6.85 | ppl   946.10\n",
      "| epoch  74 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.16 | loss  6.84 | ppl   938.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 40.16s | valid loss  6.75 | valid ppl   855.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |   200/ 1024 batches | lr 0.00 | ms/batch 37.48 | loss  6.89 | ppl   977.97\n",
      "| epoch  75 |   400/ 1024 batches | lr 0.00 | ms/batch 39.90 | loss  6.87 | ppl   961.92\n",
      "| epoch  75 |   600/ 1024 batches | lr 0.00 | ms/batch 37.94 | loss  6.86 | ppl   955.90\n",
      "| epoch  75 |   800/ 1024 batches | lr 0.00 | ms/batch 37.73 | loss  6.86 | ppl   949.08\n",
      "| epoch  75 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.84 | loss  6.85 | ppl   942.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 41.09s | valid loss  6.75 | valid ppl   850.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |   200/ 1024 batches | lr 0.00 | ms/batch 38.58 | loss  6.89 | ppl   981.34\n",
      "| epoch  76 |   400/ 1024 batches | lr 0.00 | ms/batch 37.90 | loss  6.87 | ppl   965.07\n",
      "| epoch  76 |   600/ 1024 batches | lr 0.00 | ms/batch 37.61 | loss  6.87 | ppl   958.55\n",
      "| epoch  76 |   800/ 1024 batches | lr 0.00 | ms/batch 38.44 | loss  6.86 | ppl   952.14\n",
      "| epoch  76 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.74 | loss  6.85 | ppl   945.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 40.55s | valid loss  6.74 | valid ppl   845.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |   200/ 1024 batches | lr 0.00 | ms/batch 37.54 | loss  6.89 | ppl   984.76\n",
      "| epoch  77 |   400/ 1024 batches | lr 0.00 | ms/batch 37.45 | loss  6.88 | ppl   968.25\n",
      "| epoch  77 |   600/ 1024 batches | lr 0.00 | ms/batch 39.34 | loss  6.87 | ppl   961.26\n",
      "| epoch  77 |   800/ 1024 batches | lr 0.00 | ms/batch 37.92 | loss  6.86 | ppl   955.03\n",
      "| epoch  77 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.58 | loss  6.85 | ppl   948.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 40.34s | valid loss  6.73 | valid ppl   840.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |   200/ 1024 batches | lr 0.00 | ms/batch 37.70 | loss  6.90 | ppl   988.29\n",
      "| epoch  78 |   400/ 1024 batches | lr 0.00 | ms/batch 39.57 | loss  6.88 | ppl   971.34\n",
      "| epoch  78 |   600/ 1024 batches | lr 0.00 | ms/batch 39.21 | loss  6.87 | ppl   963.67\n",
      "| epoch  78 |   800/ 1024 batches | lr 0.00 | ms/batch 37.61 | loss  6.86 | ppl   958.03\n",
      "| epoch  78 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.71 | loss  6.86 | ppl   951.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 40.92s | valid loss  6.73 | valid ppl   836.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |   200/ 1024 batches | lr 0.00 | ms/batch 38.35 | loss  6.90 | ppl   991.54\n",
      "| epoch  79 |   400/ 1024 batches | lr 0.00 | ms/batch 37.17 | loss  6.88 | ppl   974.43\n",
      "| epoch  79 |   600/ 1024 batches | lr 0.00 | ms/batch 38.22 | loss  6.87 | ppl   966.06\n",
      "| epoch  79 |   800/ 1024 batches | lr 0.00 | ms/batch 38.53 | loss  6.87 | ppl   960.98\n",
      "| epoch  79 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.58 | loss  6.86 | ppl   953.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 40.04s | valid loss  6.73 | valid ppl   833.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |   200/ 1024 batches | lr 0.00 | ms/batch 39.39 | loss  6.90 | ppl   994.74\n",
      "| epoch  80 |   400/ 1024 batches | lr 0.00 | ms/batch 38.54 | loss  6.88 | ppl   977.21\n",
      "| epoch  80 |   600/ 1024 batches | lr 0.00 | ms/batch 39.73 | loss  6.88 | ppl   968.20\n",
      "| epoch  80 |   800/ 1024 batches | lr 0.00 | ms/batch 38.13 | loss  6.87 | ppl   963.83\n",
      "| epoch  80 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.52 | loss  6.86 | ppl   956.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 40.77s | valid loss  6.72 | valid ppl   830.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 |   200/ 1024 batches | lr 0.00 | ms/batch 38.72 | loss  6.91 | ppl   997.61\n",
      "| epoch  81 |   400/ 1024 batches | lr 0.00 | ms/batch 38.24 | loss  6.89 | ppl   979.96\n",
      "| epoch  81 |   600/ 1024 batches | lr 0.00 | ms/batch 38.60 | loss  6.88 | ppl   970.40\n",
      "| epoch  81 |   800/ 1024 batches | lr 0.00 | ms/batch 39.99 | loss  6.87 | ppl   966.54\n",
      "| epoch  81 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.08 | loss  6.87 | ppl   958.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 41.29s | valid loss  6.72 | valid ppl   827.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |   200/ 1024 batches | lr 0.00 | ms/batch 37.91 | loss  6.91 | ppl  1000.35\n",
      "| epoch  82 |   400/ 1024 batches | lr 0.00 | ms/batch 37.79 | loss  6.89 | ppl   982.60\n",
      "| epoch  82 |   600/ 1024 batches | lr 0.00 | ms/batch 38.67 | loss  6.88 | ppl   972.37\n",
      "| epoch  82 |   800/ 1024 batches | lr 0.00 | ms/batch 39.46 | loss  6.88 | ppl   969.24\n",
      "| epoch  82 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.76 | loss  6.87 | ppl   960.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 40.62s | valid loss  6.72 | valid ppl   824.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |   200/ 1024 batches | lr 0.00 | ms/batch 37.72 | loss  6.91 | ppl  1002.99\n",
      "| epoch  83 |   400/ 1024 batches | lr 0.00 | ms/batch 40.82 | loss  6.89 | ppl   984.88\n",
      "| epoch  83 |   600/ 1024 batches | lr 0.00 | ms/batch 38.95 | loss  6.88 | ppl   974.32\n",
      "| epoch  83 |   800/ 1024 batches | lr 0.00 | ms/batch 39.51 | loss  6.88 | ppl   971.58\n",
      "| epoch  83 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.81 | loss  6.87 | ppl   962.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 41.77s | valid loss  6.71 | valid ppl   822.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |   200/ 1024 batches | lr 0.00 | ms/batch 39.68 | loss  6.91 | ppl  1005.45\n",
      "| epoch  84 |   400/ 1024 batches | lr 0.00 | ms/batch 37.62 | loss  6.89 | ppl   986.91\n",
      "| epoch  84 |   600/ 1024 batches | lr 0.00 | ms/batch 39.53 | loss  6.88 | ppl   976.34\n",
      "| epoch  84 |   800/ 1024 batches | lr 0.00 | ms/batch 38.97 | loss  6.88 | ppl   973.85\n",
      "| epoch  84 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.15 | loss  6.87 | ppl   964.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 41.09s | valid loss  6.71 | valid ppl   820.90\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  85 |   200/ 1024 batches | lr 0.00 | ms/batch 38.42 | loss  6.92 | ppl  1007.81\n",
      "| epoch  85 |   400/ 1024 batches | lr 0.00 | ms/batch 40.00 | loss  6.90 | ppl   988.74\n",
      "| epoch  85 |   600/ 1024 batches | lr 0.00 | ms/batch 40.06 | loss  6.89 | ppl   978.38\n",
      "| epoch  85 |   800/ 1024 batches | lr 0.00 | ms/batch 38.94 | loss  6.88 | ppl   975.94\n",
      "| epoch  85 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.51 | loss  6.87 | ppl   966.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 41.26s | valid loss  6.71 | valid ppl   819.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |   200/ 1024 batches | lr 0.00 | ms/batch 39.48 | loss  6.92 | ppl  1010.01\n",
      "| epoch  86 |   400/ 1024 batches | lr 0.00 | ms/batch 38.35 | loss  6.90 | ppl   990.31\n",
      "| epoch  86 |   600/ 1024 batches | lr 0.00 | ms/batch 37.30 | loss  6.89 | ppl   980.38\n",
      "| epoch  86 |   800/ 1024 batches | lr 0.00 | ms/batch 39.05 | loss  6.89 | ppl   977.69\n",
      "| epoch  86 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.25 | loss  6.87 | ppl   967.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 40.85s | valid loss  6.71 | valid ppl   817.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |   200/ 1024 batches | lr 0.00 | ms/batch 38.48 | loss  6.92 | ppl  1012.09\n",
      "| epoch  87 |   400/ 1024 batches | lr 0.00 | ms/batch 37.85 | loss  6.90 | ppl   991.60\n",
      "| epoch  87 |   600/ 1024 batches | lr 0.00 | ms/batch 39.96 | loss  6.89 | ppl   982.51\n",
      "| epoch  87 |   800/ 1024 batches | lr 0.00 | ms/batch 39.44 | loss  6.89 | ppl   979.30\n",
      "| epoch  87 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.75 | loss  6.88 | ppl   969.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 40.98s | valid loss  6.71 | valid ppl   816.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |   200/ 1024 batches | lr 0.00 | ms/batch 37.70 | loss  6.92 | ppl  1014.02\n",
      "| epoch  88 |   400/ 1024 batches | lr 0.00 | ms/batch 38.76 | loss  6.90 | ppl   992.78\n",
      "| epoch  88 |   600/ 1024 batches | lr 0.00 | ms/batch 38.18 | loss  6.89 | ppl   984.60\n",
      "| epoch  88 |   800/ 1024 batches | lr 0.00 | ms/batch 38.49 | loss  6.89 | ppl   980.64\n",
      "| epoch  88 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.47 | loss  6.88 | ppl   970.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 40.62s | valid loss  6.70 | valid ppl   815.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |   200/ 1024 batches | lr 0.00 | ms/batch 38.73 | loss  6.92 | ppl  1015.79\n",
      "| epoch  89 |   400/ 1024 batches | lr 0.00 | ms/batch 38.18 | loss  6.90 | ppl   993.76\n",
      "| epoch  89 |   600/ 1024 batches | lr 0.00 | ms/batch 38.72 | loss  6.89 | ppl   986.64\n",
      "| epoch  89 |   800/ 1024 batches | lr 0.00 | ms/batch 38.64 | loss  6.89 | ppl   981.90\n",
      "| epoch  89 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.59 | loss  6.88 | ppl   971.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 40.68s | valid loss  6.70 | valid ppl   814.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |   200/ 1024 batches | lr 0.00 | ms/batch 38.66 | loss  6.93 | ppl  1017.48\n",
      "| epoch  90 |   400/ 1024 batches | lr 0.00 | ms/batch 39.95 | loss  6.90 | ppl   994.63\n",
      "| epoch  90 |   600/ 1024 batches | lr 0.00 | ms/batch 39.89 | loss  6.90 | ppl   988.57\n",
      "| epoch  90 |   800/ 1024 batches | lr 0.00 | ms/batch 37.67 | loss  6.89 | ppl   982.96\n",
      "| epoch  90 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.66 | loss  6.88 | ppl   972.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 40.89s | valid loss  6.70 | valid ppl   813.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  91 |   200/ 1024 batches | lr 0.00 | ms/batch 39.66 | loss  6.93 | ppl  1018.98\n",
      "| epoch  91 |   400/ 1024 batches | lr 0.00 | ms/batch 38.84 | loss  6.90 | ppl   995.48\n",
      "| epoch  91 |   600/ 1024 batches | lr 0.00 | ms/batch 37.91 | loss  6.90 | ppl   990.39\n",
      "| epoch  91 |   800/ 1024 batches | lr 0.00 | ms/batch 39.98 | loss  6.89 | ppl   983.94\n",
      "| epoch  91 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.64 | loss  6.88 | ppl   974.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 41.37s | valid loss  6.70 | valid ppl   812.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |   200/ 1024 batches | lr 0.00 | ms/batch 38.36 | loss  6.93 | ppl  1020.27\n",
      "| epoch  92 |   400/ 1024 batches | lr 0.00 | ms/batch 38.92 | loss  6.90 | ppl   996.21\n",
      "| epoch  92 |   600/ 1024 batches | lr 0.00 | ms/batch 38.53 | loss  6.90 | ppl   992.15\n",
      "| epoch  92 |   800/ 1024 batches | lr 0.00 | ms/batch 39.53 | loss  6.89 | ppl   984.78\n",
      "| epoch  92 |  1000/ 1024 batches | lr 0.00 | ms/batch 40.46 | loss  6.88 | ppl   975.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 41.37s | valid loss  6.70 | valid ppl   811.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |   200/ 1024 batches | lr 0.00 | ms/batch 39.31 | loss  6.93 | ppl  1021.40\n",
      "| epoch  93 |   400/ 1024 batches | lr 0.00 | ms/batch 38.87 | loss  6.90 | ppl   996.99\n",
      "| epoch  93 |   600/ 1024 batches | lr 0.00 | ms/batch 39.55 | loss  6.90 | ppl   993.71\n",
      "| epoch  93 |   800/ 1024 batches | lr 0.00 | ms/batch 37.78 | loss  6.89 | ppl   985.54\n",
      "| epoch  93 |  1000/ 1024 batches | lr 0.00 | ms/batch 37.69 | loss  6.88 | ppl   976.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 40.74s | valid loss  6.70 | valid ppl   810.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |   200/ 1024 batches | lr 0.00 | ms/batch 39.81 | loss  6.93 | ppl  1022.42\n",
      "| epoch  94 |   400/ 1024 batches | lr 0.00 | ms/batch 38.66 | loss  6.91 | ppl   997.76\n",
      "| epoch  94 |   600/ 1024 batches | lr 0.00 | ms/batch 39.38 | loss  6.90 | ppl   995.12\n",
      "| epoch  94 |   800/ 1024 batches | lr 0.00 | ms/batch 39.99 | loss  6.89 | ppl   986.17\n",
      "| epoch  94 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.44 | loss  6.88 | ppl   977.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 41.42s | valid loss  6.70 | valid ppl   809.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |   200/ 1024 batches | lr 0.00 | ms/batch 37.66 | loss  6.93 | ppl  1023.32\n",
      "| epoch  95 |   400/ 1024 batches | lr 0.00 | ms/batch 40.11 | loss  6.91 | ppl   998.52\n",
      "| epoch  95 |   600/ 1024 batches | lr 0.00 | ms/batch 39.62 | loss  6.90 | ppl   996.42\n",
      "| epoch  95 |   800/ 1024 batches | lr 0.00 | ms/batch 40.00 | loss  6.89 | ppl   986.69\n",
      "| epoch  95 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.88 | loss  6.89 | ppl   978.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 41.69s | valid loss  6.70 | valid ppl   809.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |   200/ 1024 batches | lr 0.00 | ms/batch 40.06 | loss  6.93 | ppl  1024.07\n",
      "| epoch  96 |   400/ 1024 batches | lr 0.00 | ms/batch 37.69 | loss  6.91 | ppl   999.20\n",
      "| epoch  96 |   600/ 1024 batches | lr 0.00 | ms/batch 37.60 | loss  6.91 | ppl   997.53\n",
      "| epoch  96 |   800/ 1024 batches | lr 0.00 | ms/batch 38.08 | loss  6.89 | ppl   987.27\n",
      "| epoch  96 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.67 | loss  6.89 | ppl   978.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 40.74s | valid loss  6.70 | valid ppl   808.37\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  97 |   200/ 1024 batches | lr 0.00 | ms/batch 40.12 | loss  6.93 | ppl  1024.70\n",
      "| epoch  97 |   400/ 1024 batches | lr 0.00 | ms/batch 38.61 | loss  6.91 | ppl   999.84\n",
      "| epoch  97 |   600/ 1024 batches | lr 0.00 | ms/batch 38.83 | loss  6.91 | ppl   998.58\n",
      "| epoch  97 |   800/ 1024 batches | lr 0.00 | ms/batch 38.26 | loss  6.90 | ppl   987.71\n",
      "| epoch  97 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.98 | loss  6.89 | ppl   979.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 41.03s | valid loss  6.69 | valid ppl   807.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |   200/ 1024 batches | lr 0.00 | ms/batch 38.10 | loss  6.93 | ppl  1025.24\n",
      "| epoch  98 |   400/ 1024 batches | lr 0.00 | ms/batch 38.56 | loss  6.91 | ppl  1000.58\n",
      "| epoch  98 |   600/ 1024 batches | lr 0.00 | ms/batch 39.47 | loss  6.91 | ppl   999.39\n",
      "| epoch  98 |   800/ 1024 batches | lr 0.00 | ms/batch 38.49 | loss  6.90 | ppl   988.18\n",
      "| epoch  98 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.56 | loss  6.89 | ppl   980.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 40.77s | valid loss  6.69 | valid ppl   807.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |   200/ 1024 batches | lr 0.00 | ms/batch 37.93 | loss  6.93 | ppl  1025.67\n",
      "| epoch  99 |   400/ 1024 batches | lr 0.00 | ms/batch 40.49 | loss  6.91 | ppl  1001.18\n",
      "| epoch  99 |   600/ 1024 batches | lr 0.00 | ms/batch 37.83 | loss  6.91 | ppl  1000.16\n",
      "| epoch  99 |   800/ 1024 batches | lr 0.00 | ms/batch 38.07 | loss  6.90 | ppl   988.57\n",
      "| epoch  99 |  1000/ 1024 batches | lr 0.00 | ms/batch 39.32 | loss  6.89 | ppl   980.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 40.88s | valid loss  6.69 | valid ppl   806.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |   200/ 1024 batches | lr 0.00 | ms/batch 39.22 | loss  6.93 | ppl  1026.00\n",
      "| epoch 100 |   400/ 1024 batches | lr 0.00 | ms/batch 38.45 | loss  6.91 | ppl  1001.87\n",
      "| epoch 100 |   600/ 1024 batches | lr 0.00 | ms/batch 38.35 | loss  6.91 | ppl  1000.81\n",
      "| epoch 100 |   800/ 1024 batches | lr 0.00 | ms/batch 39.19 | loss  6.90 | ppl   988.90\n",
      "| epoch 100 |  1000/ 1024 batches | lr 0.00 | ms/batch 38.78 | loss  6.89 | ppl   981.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 40.95s | valid loss  6.69 | valid ppl   806.01\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 100 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "atlantic-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.51 | test ppl   246.12\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "heard-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter):\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "train,test,example = WikiText2()\n",
    "example = data_process(example)\n",
    "example = batchify(example, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "missing-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([35, 20])\n",
      "y torch.Size([700])\n"
     ]
    }
   ],
   "source": [
    "x,y = get_batch(example, 4)\n",
    "print(\"x\", x.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "injured-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2086, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "output = model(x.to(device), src_mask)\n",
    "labels = torch.argmax(output, 2).view(-1)\n",
    "correct_predictions = labels.eq(y)\n",
    "print(correct_predictions.sum().float() / correct_predictions.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "wrong-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0131, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t = x[:, 12:13]\n",
    "yy = y.reshape(x.size())[:, 0:1]\n",
    "\n",
    "\n",
    "output = model(t.to(device), src_mask)\n",
    "labels = torch.argmax(output, 2).view(-1)\n",
    "correct_predictions = labels.eq(yy)\n",
    "print(correct_predictions.sum().float() / correct_predictions.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ultimate-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the time of his marriage , william ' s father , john yeats , was studying law , but would later pursue art studies at <unk> school of fine art , in london . william ' s mother , susan mary <unk> , came from <unk> , from a wealthy merchant family , which owned a ||private property . he was married to elizabeth , who was born in <unk> , and died soon after his father died . = = = family = = = = = = = = = = = = = = = = early life = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n"
     ]
    }
   ],
   "source": [
    "def write_sentence(xx):\n",
    "    sentence = \"\"\n",
    "    for word in tensor_to_tokens(xx.reshape(-1)):\n",
    "        sentence+= word +\" \"\n",
    "    print(sentence)\n",
    "    \n",
    "def complete_sentence(xx, length, src_mask):\n",
    "    sentence = \"\"\n",
    "    for word in tensor_to_tokens(xx.reshape(-1)):\n",
    "        sentence+= word +\" \"\n",
    "    sentence += \"||\"\n",
    "    # crete new tokens\n",
    "    for _ in range(length):\n",
    "        out = model(xx.to(device), src_mask)\n",
    "        labels = torch.argmax(out, 2).view(-1)\n",
    "        sentence += tensor_to_tokens(labels.reshape(-1))[-1]+\" \"\n",
    "        xx = torch.cat((xx[0:], labels.reshape(-1)[-1:].reshape(1,1)))\n",
    "        src_mask = model.generate_square_subsequent_mask(len(xx)).to(device)\n",
    "    \n",
    "    print(sentence)\n",
    "    \n",
    "    \n",
    "t = \"At the time of his marriage, William's father, John Yeats, was studying law, but would later pursue art studies at Heatherley School of Fine Art, in London. William's mother, Susan Mary Pollexfen, came from Sligo, from a wealthy merchant family, which owned a\"\n",
    "t = torch.tensor(vocab(tokenizer(t)))\n",
    "src_mask = model.generate_square_subsequent_mask(len(t)).to(device)\n",
    "t = t.reshape([-1, 1]).to(device)\n",
    "\n",
    "complete_sentence(t, 100, src_mask)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-revision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-seattle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
